{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config file config1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from joblib import Parallel, delayed\n",
    "# import seaborn as sns\n",
    "import scipy as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append(\"/home/hhl/바탕화면/dacon/dacon21/model/using_cofing\")\n",
    "# sys.argv = ['--config', 'config1_try']\n",
    "sys.argv = ['--config', 'config1']\n",
    "\n",
    "from models import *\n",
    "from loss import *\n",
    "from run import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config1:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    channels_last=False\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b3_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=12\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=1028\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config1/tf_efficientnet_b3_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config2:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus=0\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    channels_last=False\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b4_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45\n",
    "    arcface_m=0.4\n",
    "    head='arc_margin'\n",
    "    neck='option-D'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=7\n",
    "    n_splits = 5\n",
    "    fold=0\n",
    "    seed=794621\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config2/tf_efficientnet_b4_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config3:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b2_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=15\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=756\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config4/tf_efficientnet_b2_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config4:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b3_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=9\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=204\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config3/tf_efficientnet_b3_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config5:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b2_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=12\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=1214\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config5/tf_efficientnet_b2_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config6:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b1_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=9\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=9999\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config6/tf_efficientnet_b1_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config7:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b1_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=9\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=9999\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config7/tf_efficientnet_b1_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config8:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b1_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=9\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=9999\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config8/tf_efficientnet_b1_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config9:\n",
    "    DEBUG=False\n",
    "    num_workers=8\n",
    "    gpus='0'\n",
    "    distributed_backend=None\n",
    "    sync_batchnorm=True\n",
    "    gradient_accumulation_steps=4\n",
    "    precision=16\n",
    "    warmup_epo=1\n",
    "    cosine_epo=19\n",
    "    lr=0.002\n",
    "    weight_decay=0.0001\n",
    "    p_trainable=True\n",
    "    crit='bce'\n",
    "    backbone='tf_efficientnet_b1_ns'\n",
    "    embedding_size=512\n",
    "    pool='gem'\n",
    "    arcface_s=45.0\n",
    "    arcface_m=0.4\n",
    "    neck='option-D'\n",
    "    head='arc_margin'\n",
    "    pretrained_weights=None\n",
    "    optim='sgd'\n",
    "    batch_size=9\n",
    "    n_splits=5\n",
    "    fold=0\n",
    "    seed=9999\n",
    "    device='cuda:0'\n",
    "    out_dim=1049\n",
    "    n_classes=1049\n",
    "    class_weights='log'\n",
    "    class_weights_norm='batch'\n",
    "    normalization='imagenet'\n",
    "    crop_size=448\n",
    "    model='/home/hhl/바탕화면/dacon/dacon21/model/config9/tf_efficientnet_b1_ns_best_fold_0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataset(Dataset): \n",
    "    def __init__(self, csv): \n",
    "        self.csv = csv.filepath.values\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.csv[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img1 = val_aug1(image=img)['image'].astype(np.float32)\n",
    "        img1 = self.normalize_img(img1)\n",
    "        tensor1 = self.to_torch_tensor(img1)\n",
    "        feature_dict1 = {'idx':torch.tensor(index).long(), 'input':tensor1}\n",
    "\n",
    "        img2 = val_aug2(image=img)['image'].astype(np.float32)\n",
    "        img2 = self.normalize_img(img2)\n",
    "        tensor2 = self.to_torch_tensor(img2)\n",
    "        feature_dict2 = {'idx':torch.tensor(index).long(), 'input':tensor2}\n",
    "\n",
    "        img3 = val_aug3(image=img)['image'].astype(np.float32)\n",
    "        img3 = self.normalize_img(img3)\n",
    "        tensor3 = self.to_torch_tensor(img3)\n",
    "        feature_dict3 = {'idx':torch.tensor(index).long(), 'input':tensor3}\n",
    "\n",
    "        img4 = val_aug4(image=img)['image'].astype(np.float32)\n",
    "        img4 = self.normalize_img(img4)\n",
    "        tensor4 = self.to_torch_tensor(img4)\n",
    "        feature_dict4 = {'idx':torch.tensor(index).long(), 'input':tensor4}\n",
    "\n",
    "        img5 = val_aug4(image=img)['image'].astype(np.float32)\n",
    "        img5 = self.normalize_img(img5)\n",
    "        tensor5 = self.to_torch_tensor(img5)\n",
    "        feature_dict5 = {'idx':torch.tensor(index).long(), 'input':tensor5}\n",
    "        return feature_dict1, feature_dict2, feature_dict3, feature_dict4, feature_dict5\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.csv)\n",
    "    def normalize_img(self,img):\n",
    "        mean = np.array([123.675, 116.28 , 103.53 ], dtype=np.float32)\n",
    "        std = np.array([58.395   , 57.120, 57.375 ], dtype=np.float32)\n",
    "        img = img.astype(np.float32)\n",
    "        img -= mean\n",
    "        img *= np.reciprocal(std, dtype=np.float32)\n",
    "        return img\n",
    "    def to_torch_tensor(self,img):\n",
    "        return torch.from_numpy(img.transpose((2, 0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_aug1 = A.Compose([ \n",
    "    A.LongestMaxSize(664,p=1),\n",
    "    A.PadIfNeeded(664, 664, border_mode=cv2.BORDER_CONSTANT,p=1),\n",
    "    A.CenterCrop(always_apply=False, p=1.0, height=config1.crop_size, width=config1.crop_size), \n",
    "    ], p=1.0\n",
    "    )\n",
    "\n",
    "val_aug2 = A.Compose([\n",
    "        A.ImageCompression(quality_lower=99, quality_upper=100),    \n",
    "        A.Resize(512, 512),\n",
    "    ])\n",
    "\n",
    "val_aug3 = A.Compose([\n",
    "        A.ImageCompression(quality_lower=99, quality_upper=100),    \n",
    "        A.Resize(448, 448),\n",
    "    ])\n",
    "\n",
    "val_aug4 = A.Compose([\n",
    "        A.ImageCompression(quality_lower=99, quality_upper=100),    \n",
    "        A.Resize(768, 768),\n",
    "    ])\n",
    "\n",
    "val_aug5 = A.Compose([\n",
    "        A.ImageCompression(quality_lower=99, quality_upper=100),    \n",
    "        A.Resize(484, 484),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, valid_loader):\n",
    "    from tqdm import tqdm\n",
    "    model.eval()\n",
    "    val_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            batch['input'] = batch['input'].to(args.device)\n",
    "\n",
    "            output_dict = model(batch, get_embeddings=True)\n",
    "            logits = output_dict['logits']\n",
    "            embeddings = output_dict['embeddings']   \n",
    "\n",
    "            output = dict({\n",
    "                'idx':batch['idx'].detach().cpu().numpy().astype(int),\n",
    "                'embeddings': embeddings.detach().cpu().numpy(),\n",
    "                \n",
    "            })\n",
    "            val_outputs += [output] \n",
    "    return val_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "train = pd.read_csv('../data/public/train.csv')\n",
    "train['filepath'] = [os.path.join('../data/train', str(lm_id), str(id)+'.JPG') for lm_id, id in zip(train['landmark_id'], train['id'])]\n",
    "sub = pd.read_csv('../data/public/sample_submission.csv')\n",
    "sub['filepath'] = [os.path.join('../data/public/test', id, folder+'.JPG') for id, folder in zip(sub['id'].apply(lambda x: x[0]), sub['id'])]\n",
    "\n",
    "train_dataset = LMDataset(train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=36, num_workers=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "test_dataset = LMDataset(sub)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=36, num_workers=8, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Net(config1)\n",
    "model2 = Net(config2)\n",
    "model3 = Net(config3)\n",
    "model4 = Net(config4)\n",
    "model5 = Net(config5)\n",
    "model6 = Net(config6)\n",
    "model7 = Net(config7)\n",
    "model8 = Net(config8)\n",
    "model9 = Net(config9)\n",
    "\n",
    "model1 = model1.to('cuda:0')\n",
    "model2 = model2.to('cuda:0')\n",
    "model3 = model3.to('cuda:0')\n",
    "model4 = model4.to('cuda:0')\n",
    "model5 = model5.to('cuda:0')\n",
    "model6 = model6.to('cuda:0')\n",
    "model7 = model7.to('cuda:0')\n",
    "model8 = model8.to('cuda:0')\n",
    "model9 = model9.to('cuda:0')\n",
    "\n",
    "model1.load_state_dict(torch.load(config1.model))\n",
    "model2.load_state_dict(torch.load(config2.model))\n",
    "model3.load_state_dict(torch.load(config3.model))\n",
    "model4.load_state_dict(torch.load(config4.model))\n",
    "model5.load_state_dict(torch.load(config5.model))\n",
    "model6.load_state_dict(torch.load(config6.model))\n",
    "model7.load_state_dict(torch.load(config7.model))\n",
    "model8.load_state_dict(torch.load(config8.model))\n",
    "model9.load_state_dict(torch.load(config9.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2448/2448 [1:12:21<00:00,  1.77s/it]\n",
      "100%|██████████| 1055/1055 [31:24<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "CLS_TOP_K=5\n",
    "TOP_K=5\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()\n",
    "model6.eval()\n",
    "model7.eval()\n",
    "model8.eval()\n",
    "model9.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feats = []\n",
    "    for batch, batch2, batch3, batch4, batch5 in tqdm(train_loader):\n",
    "        batch['input'] = batch['input'].to('cuda:0')\n",
    "        batch2['input'] = batch2['input'].to('cuda:0')\n",
    "        batch3['input'] = batch3['input'].to('cuda:0')\n",
    "        batch4['input'] = batch4['input'].to('cuda:0')\n",
    "        batch5['input'] = batch5['input'].to('cuda:0')\n",
    "        \n",
    "        output_dict1 = model1(batch, get_embeddings=True)\n",
    "        output_dict2 = model2(batch2, get_embeddings=True)\n",
    "        output_dict3 = model3(batch2, get_embeddings=True)\n",
    "        output_dict4 = model4(batch3, get_embeddings=True)\n",
    "        output_dict5 = model5(batch2, get_embeddings=True)\n",
    "        output_dict6 = model6(batch2, get_embeddings=True)\n",
    "        output_dict7 = model7(batch4, get_embeddings=True)\n",
    "        output_dict8 = model8(batch3, get_embeddings=True)\n",
    "        output_dict9 = model9(batch5, get_embeddings=True)\n",
    "        \n",
    "        feat = torch.cat([output_dict1['embeddings'], output_dict2['embeddings'], output_dict3['embeddings'],output_dict4['embeddings'], output_dict5['embeddings'], output_dict6['embeddings'], output_dict7['embeddings'], output_dict8['embeddings'], output_dict9['embeddings']], dim=1)\n",
    "        feats.append(feat.detach().cpu())\n",
    "    else:\n",
    "        feats = torch.cat(feats)\n",
    "        feats = feats.to('cuda:0')\n",
    "        feats = F.normalize(feats)\n",
    "        \n",
    "    PRODS = []\n",
    "    PREDS = []\n",
    "    PRODS_M = []\n",
    "    PREDS_M = []     \n",
    "    \n",
    "    for batch, batch2, batch3, batch4, batch5 in tqdm(test_loader):\n",
    "        batch['input'] = batch['input'].to('cuda:0')\n",
    "        batch2['input'] = batch2['input'].to('cuda:0')\n",
    "        batch3['input'] = batch3['input'].to('cuda:0')\n",
    "        batch4['input'] = batch4['input'].to('cuda:0')\n",
    "        batch5['input'] = batch5['input'].to('cuda:0')\n",
    "        \n",
    "\n",
    "        output_dict = model1(batch,  get_embeddings=True) ; logits =  output_dict['logits'] ; embeddings1 = output_dict['embedding']\n",
    "        output_dict = model2(batch2, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings2 = output_dict['embedding']\n",
    "        output_dict = model3(batch2, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings3 = output_dict['embedding']\n",
    "        output_dict = model4(batch3, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings4 = output_dict['embedding']\n",
    "        output_dict = model5(batch2, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings5 = output_dict['embedding']\n",
    "        output_dict = model6(batch2, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings6 = output_dict['embedding']\n",
    "        output_dict = model7(batch4, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings7 = output_dict['embedding']\n",
    "        output_dict = model8(batch3, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings8 = output_dict['embedding']\n",
    "        output_dict = model9(batch5, get_embeddings=True) ; logits += output_dict['logits'] ; embeddings9 = output_dict['embedding']\n",
    "        \n",
    "\n",
    "        feat = torch.cat([embeddings1, embeddings2, embeddings3, embeddings4, embeddings5, embeddings6, embeddings7, embeddings8, embeddings9], dim=1)\n",
    "        feat = F.normalize(feat)\n",
    "        \n",
    "        logits=logits/9\n",
    "        \n",
    "        (values, indices) = torch.topk(logits, CLS_TOP_K, dim=1)\n",
    "        probs_m = values\n",
    "        preds_m = indices  \n",
    "        \n",
    "        PRODS_M.append(probs_m.detach().cpu())\n",
    "        PREDS_M.append(preds_m.detach().cpu())  \n",
    "        \n",
    "        distance = feat.mm(feats.t())\n",
    "        (values, indices) = torch.topk(distance, TOP_K, dim=1)\n",
    "        probs = values\n",
    "        preds = indices\n",
    "        PRODS.append(probs.detach().cpu())\n",
    "        PREDS.append(preds.detach().cpu())\n",
    "        \n",
    "    PRODS = torch.cat(PRODS).numpy()\n",
    "    PREDS = torch.cat(PREDS).numpy()\n",
    "    PRODS_M = torch.cat(PRODS_M).numpy()\n",
    "    PREDS_M = torch.cat(PREDS_M).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9681861 , 0.9588182 , 0.95706064, 0.95588136, 0.95040643],\n",
       "       [0.96667993, 0.9472121 , 0.9447556 , 0.9408512 , 0.94078714],\n",
       "       [0.9377258 , 0.912168  , 0.90437233, 0.88918334, 0.88405263],\n",
       "       ...,\n",
       "       [0.9671086 , 0.96655184, 0.9575849 , 0.9565214 , 0.94599533],\n",
       "       [0.9174435 , 0.90726936, 0.90146875, 0.89430594, 0.89088726],\n",
       "       [0.9650006 , 0.9605202 , 0.9572787 , 0.94926447, 0.94199556]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46165, 46223, 46177, 46178, 46214],\n",
       "       [46212, 46166, 46164, 46178, 46193],\n",
       "       [46179, 46204, 46238, 46212, 46206],\n",
       "       ...,\n",
       "       [87205, 87197, 87263, 87269, 87247],\n",
       "       [87230, 87197, 87205, 87269, 87263],\n",
       "       [87269, 87263, 87205, 87197, 87196]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8262315 , 0.17035033, 0.16999641, 0.16363013, 0.16199456],\n",
       "       [0.8278582 , 0.16406849, 0.1602645 , 0.15817578, 0.15451196],\n",
       "       [0.79496634, 0.1899417 , 0.18392396, 0.17450395, 0.16595139],\n",
       "       ...,\n",
       "       [0.82473266, 0.24279721, 0.17697482, 0.1700898 , 0.16491812],\n",
       "       [0.8146967 , 0.22368771, 0.16808186, 0.15954326, 0.15771452],\n",
       "       [0.81549466, 0.2523113 , 0.16957906, 0.16657   , 0.16497181]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRODS_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,  547,  674,  524,  184],\n",
       "       [ 956,  547,  524,  849, 1040],\n",
       "       [ 956,  184,  557,  547,  496],\n",
       "       ...,\n",
       "       [ 901,  675,  555,   94,  655],\n",
       "       [ 901,  675,  555,  613,   52],\n",
       "       [ 901,  675,  325,  856,  555]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDS_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ensembles/PRODS.npy', PRODS)\n",
    "np.save('ensembles/PREDS.npy', PREDS)\n",
    "np.save('ensembles/PREDS_M.npy', PREDS_M)\n",
    "np.save('ensembles/PREDS_M.npy', PREDS_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark = train['landmark_id'].values\n",
    "PREDS2 = landmark[PREDS]\n",
    "# PREDS_M = np.vectorize(idx2landmark_id.get)(PREDS_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dir, 'idx2landmark_id.pkl'), 'rb') as fp:\n",
    "    idx2landmark_id = pickle.load(fp)\n",
    "    landmark_id2idx = {idx2landmark_id[idx]: idx for idx in idx2landmark_id.keys()}\n",
    "    \n",
    "pred_mask = pd.Series(df.landmark_id.unique()).map(landmark_id2idx).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vectorize(idx2landmark_id.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1048, 0, 1048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDS2.min(), PREDS2.max(), PREDS_M.min(), PREDS_M.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,  547,  674,  524,  184],\n",
       "       [ 956,  547,  524,  849, 1040],\n",
       "       [ 956,  184,  557,  547,  496],\n",
       "       ...,\n",
       "       [ 901,  675,  555,   94,  655],\n",
       "       [ 901,  675,  555,  613,   52],\n",
       "       [ 901,  675,  325,  856,  555]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDS_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[956, 956, 956],\n",
       "       [956, 956, 956],\n",
       "       [956, 956, 956]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDS2[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,  547,  674,  524,  184],\n",
       "       [ 956,  547,  524,  849, 1040],\n",
       "       [ 956,  184,  557,  547,  496]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDS_M[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9681861 , 0.9588182 , 0.95706064, 0.95588136, 0.95040643],\n",
       "       [0.96667993, 0.9472121 , 0.9447556 , 0.9408512 , 0.94078714],\n",
       "       [0.9377258 , 0.912168  , 0.90437233, 0.88918334, 0.88405263]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRODS[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8262315 , 0.17035033, 0.16999641, 0.16363013, 0.16199456],\n",
       "       [0.8278582 , 0.16406849, 0.1602645 , 0.15817578, 0.15451196],\n",
       "       [0.79496634, 0.1899417 , 0.18392396, 0.17450395, 0.16595139]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRODS_M[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37964/37964 [00:00<00:00, 46493.55it/s]\n"
     ]
    }
   ],
   "source": [
    "PRODS_F = []\n",
    "PREDS_F = []\n",
    "for i in tqdm(range(PREDS2.shape[0])):\n",
    "    tmp = {}\n",
    "    classify_dict = {PREDS_M[i,j] : PRODS_M[i,j] for j in range(CLS_TOP_K)}\n",
    "    for k in range(TOP_K):\n",
    "        lid = PREDS2[i, k]\n",
    "        tmp[lid] = tmp.get(lid, 0.) + float(PRODS[i, k]) ** 9 * classify_dict.get(lid,1e-8)**10\n",
    "    pred, conf = max(tmp.items(), key=lambda x: x[1])\n",
    "    PREDS_F.append(pred)\n",
    "    PRODS_F.append(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['landmark_id']=PREDS_F\n",
    "sub['conf']=PRODS_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>956</td>\n",
       "      <td>0.504824</td>\n",
       "      <td>../data/public/test/x/xlf1tgh2ih.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>956</td>\n",
       "      <td>0.469569</td>\n",
       "      <td>../data/public/test/6/68a3ot4osk.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>956</td>\n",
       "      <td>0.209661</td>\n",
       "      <td>../data/public/test/s/si2lek4u0a.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>956</td>\n",
       "      <td>0.364817</td>\n",
       "      <td>../data/public/test/r/rmtqxhipnv.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>956</td>\n",
       "      <td>0.599650</td>\n",
       "      <td>../data/public/test/2/2flmjdud0e.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37959</th>\n",
       "      <td>8nlfrrdnwk</td>\n",
       "      <td>901</td>\n",
       "      <td>0.385468</td>\n",
       "      <td>../data/public/test/8/8nlfrrdnwk.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37960</th>\n",
       "      <td>k0w00aa3iy</td>\n",
       "      <td>901</td>\n",
       "      <td>0.428705</td>\n",
       "      <td>../data/public/test/k/k0w00aa3iy.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37961</th>\n",
       "      <td>xrp8d0pb85</td>\n",
       "      <td>901</td>\n",
       "      <td>0.499425</td>\n",
       "      <td>../data/public/test/x/xrp8d0pb85.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37962</th>\n",
       "      <td>uobnsz7na9</td>\n",
       "      <td>901</td>\n",
       "      <td>0.256282</td>\n",
       "      <td>../data/public/test/u/uobnsz7na9.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37963</th>\n",
       "      <td>4if3rbcf2d</td>\n",
       "      <td>901</td>\n",
       "      <td>0.430120</td>\n",
       "      <td>../data/public/test/4/4if3rbcf2d.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  landmark_id      conf                              filepath\n",
       "0      xlf1tgh2ih          956  0.504824  ../data/public/test/x/xlf1tgh2ih.JPG\n",
       "1      68a3ot4osk          956  0.469569  ../data/public/test/6/68a3ot4osk.JPG\n",
       "2      si2lek4u0a          956  0.209661  ../data/public/test/s/si2lek4u0a.JPG\n",
       "3      rmtqxhipnv          956  0.364817  ../data/public/test/r/rmtqxhipnv.JPG\n",
       "4      2flmjdud0e          956  0.599650  ../data/public/test/2/2flmjdud0e.JPG\n",
       "...           ...          ...       ...                                   ...\n",
       "37959  8nlfrrdnwk          901  0.385468  ../data/public/test/8/8nlfrrdnwk.JPG\n",
       "37960  k0w00aa3iy          901  0.428705  ../data/public/test/k/k0w00aa3iy.JPG\n",
       "37961  xrp8d0pb85          901  0.499425  ../data/public/test/x/xrp8d0pb85.JPG\n",
       "37962  uobnsz7na9          901  0.256282  ../data/public/test/u/uobnsz7na9.JPG\n",
       "37963  4if3rbcf2d          901  0.430120  ../data/public/test/4/4if3rbcf2d.JPG\n",
       "\n",
       "[37964 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.drop(columns=['filepath']).to_csv('../submit/baseline_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>956</td>\n",
       "      <td>0.335313</td>\n",
       "      <td>../data/public/test/x/xlf1tgh2ih.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>956</td>\n",
       "      <td>0.302072</td>\n",
       "      <td>../data/public/test/6/68a3ot4osk.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>956</td>\n",
       "      <td>0.187452</td>\n",
       "      <td>../data/public/test/s/si2lek4u0a.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>956</td>\n",
       "      <td>0.250135</td>\n",
       "      <td>../data/public/test/r/rmtqxhipnv.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>956</td>\n",
       "      <td>0.401532</td>\n",
       "      <td>../data/public/test/2/2flmjdud0e.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37959</th>\n",
       "      <td>8nlfrrdnwk</td>\n",
       "      <td>901</td>\n",
       "      <td>0.276970</td>\n",
       "      <td>../data/public/test/8/8nlfrrdnwk.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37960</th>\n",
       "      <td>k0w00aa3iy</td>\n",
       "      <td>901</td>\n",
       "      <td>0.294003</td>\n",
       "      <td>../data/public/test/k/k0w00aa3iy.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37961</th>\n",
       "      <td>xrp8d0pb85</td>\n",
       "      <td>901</td>\n",
       "      <td>0.362963</td>\n",
       "      <td>../data/public/test/x/xrp8d0pb85.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37962</th>\n",
       "      <td>uobnsz7na9</td>\n",
       "      <td>901</td>\n",
       "      <td>0.195852</td>\n",
       "      <td>../data/public/test/u/uobnsz7na9.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37963</th>\n",
       "      <td>4if3rbcf2d</td>\n",
       "      <td>901</td>\n",
       "      <td>0.282407</td>\n",
       "      <td>../data/public/test/4/4if3rbcf2d.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  landmark_id      conf                              filepath\n",
       "0      xlf1tgh2ih          956  0.335313  ../data/public/test/x/xlf1tgh2ih.JPG\n",
       "1      68a3ot4osk          956  0.302072  ../data/public/test/6/68a3ot4osk.JPG\n",
       "2      si2lek4u0a          956  0.187452  ../data/public/test/s/si2lek4u0a.JPG\n",
       "3      rmtqxhipnv          956  0.250135  ../data/public/test/r/rmtqxhipnv.JPG\n",
       "4      2flmjdud0e          956  0.401532  ../data/public/test/2/2flmjdud0e.JPG\n",
       "...           ...          ...       ...                                   ...\n",
       "37959  8nlfrrdnwk          901  0.276970  ../data/public/test/8/8nlfrrdnwk.JPG\n",
       "37960  k0w00aa3iy          901  0.294003  ../data/public/test/k/k0w00aa3iy.JPG\n",
       "37961  xrp8d0pb85          901  0.362963  ../data/public/test/x/xrp8d0pb85.JPG\n",
       "37962  uobnsz7na9          901  0.195852  ../data/public/test/u/uobnsz7na9.JPG\n",
       "37963  4if3rbcf2d          901  0.282407  ../data/public/test/4/4if3rbcf2d.JPG\n",
       "\n",
       "[37964 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_sub = pd.read_csv('../submit/baseline_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        956\n",
       "1        956\n",
       "2        956\n",
       "3        956\n",
       "4        956\n",
       "        ... \n",
       "37959    901\n",
       "37960    901\n",
       "37961    901\n",
       "37962    901\n",
       "37963    901\n",
       "Name: landmark_id, Length: 37964, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_sub['landmark_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "37959    True\n",
       "37960    True\n",
       "37961    True\n",
       "37962    True\n",
       "37963    True\n",
       "Name: landmark_id, Length: 37964, dtype: bool"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prior_sub['landmark_id']==sub['landmark_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        956\n",
       "1        956\n",
       "2        956\n",
       "3        956\n",
       "4        956\n",
       "        ... \n",
       "37959    901\n",
       "37960    901\n",
       "37961    901\n",
       "37962    901\n",
       "37963    901\n",
       "Name: landmark_id, Length: 37964, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('cloud': conda)",
   "language": "python",
   "name": "python37964bitcloudconda2e492f8b7a0c4d89873e0681c6f92d2e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
