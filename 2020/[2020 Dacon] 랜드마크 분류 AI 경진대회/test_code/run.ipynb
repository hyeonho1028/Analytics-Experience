{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import *\n",
    "from loader import *\n",
    "from models import *\n",
    "from trainer import *\n",
    "from loss import *\n",
    "from utils import *\n",
    "from scheduler import *\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "\n",
    "import albumentations as A\n",
    "import geffnet\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import *\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import expit, softmax\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def global_average_precision_score(y_true, y_pred, ignore_non_landmarks=False):\n",
    "    indexes = np.argsort(y_pred[1])[::-1]\n",
    "    queries_with_target = (y_true < args.n_classes).sum()\n",
    "    correct_predictions = 0\n",
    "    total_score = 0.\n",
    "    i = 1\n",
    "    for k in indexes:\n",
    "        if ignore_non_landmarks and y_true[k] == args.n_classes:\n",
    "            continue\n",
    "        if y_pred[0][k] == args.n_classes:\n",
    "            continue\n",
    "        relevance_of_prediction_i = 0\n",
    "        if y_true[k] == y_pred[0][k]:\n",
    "            correct_predictions += 1\n",
    "            relevance_of_prediction_i = 1\n",
    "        precision_at_rank_i = correct_predictions / i\n",
    "        total_score += precision_at_rank_i * relevance_of_prediction_i\n",
    "        i += 1\n",
    "    return 1 / queries_with_target * total_score\n",
    "\n",
    "def comp_metric(y_true, logits, ignore_non_landmarks=False):\n",
    "    \n",
    "    score = global_average_precision_score(y_true, logits, ignore_non_landmarks=ignore_non_landmarks)\n",
    "    return score\n",
    "\n",
    "def cos_similarity_matrix(a, b, eps=1e-8):\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt\n",
    "\n",
    "def get_topk_cossim(test_emb, tr_emb, batchsize = 64, k=10, device='cuda:0',verbose=True):\n",
    "    tr_emb = torch.tensor(tr_emb, dtype = torch.float32, device=torch.device(device))\n",
    "    test_emb = torch.tensor(test_emb, dtype = torch.float32, device=torch.device(device))\n",
    "    vals = []\n",
    "    inds = []\n",
    "    for test_batch in test_emb.split(batchsize):\n",
    "        sim_mat = cos_similarity_matrix(test_batch, tr_emb)\n",
    "        vals_batch, inds_batch = torch.topk(sim_mat, k=k, dim=1)\n",
    "        vals += [vals_batch.detach().cpu()]\n",
    "        inds += [inds_batch.detach().cpu()]\n",
    "    vals = torch.cat(vals)\n",
    "    inds = torch.cat(inds)\n",
    "    return vals, inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "class LMDataset(Dataset): \n",
    "    def __init__(self, csv, aug=None, normalization='simple', is_test=False): \n",
    "        self.labels = csv.landmark_id.values\n",
    "        self.csv = csv.filepath.values\n",
    "        self.aug = aug\n",
    "        self.normalization = normalization\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.csv[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.aug:\n",
    "            img = self.augment(img)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        if self.normalization:\n",
    "            img = self.normalize_img(img)\n",
    "\n",
    "        tensor = self.to_torch_tensor(img)\n",
    "        if self.is_test:\n",
    "            feature_dict = {'idx':torch.tensor(index).long(),\n",
    "                            'input':tensor}\n",
    "        else:\n",
    "            target = torch.tensor(self.labels[index])\n",
    "            feature_dict = {'idx':torch.tensor(index).long(),\n",
    "                            'input':tensor,\n",
    "                            'target':target.float().long()}\n",
    "        return feature_dict\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.csv)\n",
    "\n",
    "    def augment(self,img):\n",
    "        img_aug = self.aug(image=img)['image']\n",
    "        return img_aug.astype(np.float32)\n",
    "\n",
    "    def normalize_img(self,img):\n",
    "        if self.normalization == 'imagenet':\n",
    "            mean = np.array([123.675, 116.28 , 103.53 ], dtype=np.float32)\n",
    "            std = np.array([58.395   , 57.120, 57.375   ], dtype=np.float32)\n",
    "            img = img.astype(np.float32)\n",
    "            img -= mean\n",
    "            img *= np.reciprocal(std, dtype=np.float32)\n",
    "        elif self.normalization == 'inception':\n",
    "            mean = np.array([0.5, 0.5 , 0.5], dtype=np.float32)\n",
    "            std = np.array([0.5, 0.5 , 0.5], dtype=np.float32)\n",
    "            img = img.astype(np.float32)\n",
    "            img = img/255.\n",
    "            img = img-mean\n",
    "            img = img*np.reciprocal(std, dtype=np.float32)\n",
    "        else:\n",
    "            pass\n",
    "        return img\n",
    "    \n",
    "    def to_torch_tensor(self,img):\n",
    "        return torch.from_numpy(img.transpose((2, 0, 1)))\n",
    "\n",
    "\n",
    "def clahe(img, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "    if img.dtype != np.uint8:\n",
    "        raise TypeError(\"clahe supports only uint8 inputs\")\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        img = clahe.apply(img)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        img[:, :, 0] = clahe.apply(img[:, :, 0])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        #print(self.gamma)\n",
    "        self.eps = eps\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class ArcFaceLoss(nn.modules.Module):\n",
    "    def __init__(self, s=45.0, m=0.1, crit=\"bce\", weight=None, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        if crit == \"focal\":\n",
    "            self.crit = FocalLoss(gamma=args.focal_loss_gamma)\n",
    "        elif crit == \"bce\":\n",
    "            self.crit = nn.CrossEntropyLoss(reduction=\"none\")   \n",
    "\n",
    "        if s is None:\n",
    "            self.s = torch.nn.Parameter(torch.tensor([45.], requires_grad=True, device='cuda'))\n",
    "        else:\n",
    "            self.s = s\n",
    "\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "\n",
    "        # logits = logits.float()\n",
    "        cosine = logits\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        \n",
    "        labels2 = torch.zeros_like(cosine)\n",
    "        labels2.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "        output = (labels2 * phi) + ((1.0 - labels2) * cosine)\n",
    "\n",
    "        s = self.s\n",
    "\n",
    "        output = output * s\n",
    "        loss = self.crit(output, labels)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            w = self.weight[labels].to(logits.device)\n",
    "\n",
    "            loss = loss * w\n",
    "            ### human coding\n",
    "            class_weights_norm = 'batch'\n",
    "            if class_weights_norm == \"batch\":\n",
    "                loss = loss.sum() / w.sum()\n",
    "            if class_weights_norm == \"global\":\n",
    "                loss = loss.mean()\n",
    "            else:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            return loss\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "def loss_fn(metric_crit, target_dict, output_dict, val=False):\n",
    "    \n",
    "    y_true = target_dict['target']\n",
    "    y_pred = output_dict['logits']\n",
    "    #ignore invalid classes for val loss\n",
    "    mask = y_true < args.n_classes\n",
    "    if mask.sum() == 0:\n",
    "        return torch.zeros(1,  device = y_pred.device)\n",
    "    loss = metric_crit(y_pred[mask], y_true[mask])\n",
    "\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler  # https://github.com/ildoonet/pytorch-gradual-warmup-lr\n",
    "\n",
    "\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_last_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "class GradualWarmupScheduler(_LRScheduler):\n",
    "    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n",
    "    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n",
    "        total_epoch: target learning rate is reached at total_epoch, gradually\n",
    "        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        self.multiplier = multiplier\n",
    "        if self.multiplier < 1.:\n",
    "            raise ValueError('multiplier should be greater thant or equal to 1.')\n",
    "        self.total_epoch = total_epoch\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super(GradualWarmupScheduler, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_last_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n",
    "        if self.last_epoch <= self.total_epoch:\n",
    "            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            if epoch is None:\n",
    "                self.after_scheduler.step(metrics, None)\n",
    "            else:\n",
    "                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n",
    "\n",
    "    def step(self, epoch=None, metrics=None):\n",
    "        if type(self.after_scheduler) != ReduceLROnPlateau:\n",
    "            if self.finished and self.after_scheduler:\n",
    "                if epoch is None:\n",
    "                    self.after_scheduler.step(None)\n",
    "                else:\n",
    "                    self.after_scheduler.step(epoch - self.total_epoch)\n",
    "                self._last_lr = self.after_scheduler.get_last_lr()\n",
    "            else:\n",
    "                return super(GradualWarmupScheduler, self).step(epoch)\n",
    "        else:\n",
    "            self.step_ReduceLROnPlateau(metrics, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import *\n",
    "from utils import *\n",
    "\n",
    "#from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "import timm\n",
    "from torch import nn\n",
    "\n",
    "import geffnet\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        # stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        # self.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, features):\n",
    "        cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        return cosine\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=True):\n",
    "        super(GeM,self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1)*p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)       \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "    \n",
    "class Backbone(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, name='resnet18', pretrained=True):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.net = timm.create_model(name, pretrained=pretrained)\n",
    "        \n",
    "        if 'regnet' in name:\n",
    "            self.out_features = self.net.head.fc.in_features\n",
    "        elif 'csp' in name:\n",
    "            self.out_features = self.net.head.fc.in_features\n",
    "        elif 'res' in name: #works also for resnest\n",
    "            self.out_features = self.net.fc.in_features\n",
    "        elif 'efficientnet' in name:\n",
    "            self.out_features = self.net.classifier.in_features\n",
    "        elif 'densenet' in name:\n",
    "            self.out_features = self.net.classifier.in_features\n",
    "        elif 'senet' in name:\n",
    "            self.out_features = self.net.fc.in_features\n",
    "        elif 'inception' in name:\n",
    "            self.out_features = self.net.last_linear.in_features\n",
    "            # self.out_features = self.net.fc.in_features\n",
    "        else:\n",
    "            self.out_features = self.net.classifier.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net.forward_features(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, args, pretrained=True):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.args = args\n",
    "        self.backbone = Backbone(args.backbone, pretrained=pretrained)\n",
    "        \n",
    "        if args.pool == \"gem\":\n",
    "            self.global_pool = GeM(p_trainable=args.p_trainable)\n",
    "        elif args.pool == \"identity\":\n",
    "            self.global_pool = torch.nn.Identity()\n",
    "        else:\n",
    "            self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.embedding_size = args.embedding_size        \n",
    "        \n",
    "        # https://www.groundai.com/project/arcface-additive-angular-margin-loss-for-deep-face-recognition\n",
    "        if args.neck == \"option-D\":\n",
    "            self.neck = nn.Sequential(\n",
    "                nn.Linear(self.backbone.out_features, self.embedding_size, bias=True),\n",
    "                nn.BatchNorm1d(self.embedding_size),\n",
    "                torch.nn.PReLU()\n",
    "                # torch.nn.PReLU()\n",
    "            )\n",
    "        elif args.neck == \"option-F\":\n",
    "            self.neck = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(self.backbone.out_features, self.embedding_size, bias=True),\n",
    "                nn.BatchNorm1d(self.embedding_size),\n",
    "                torch.nn.PReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.neck = nn.Sequential(\n",
    "                nn.Linear(self.backbone.out_features, self.embedding_size, bias=False),\n",
    "                nn.BatchNorm1d(self.embedding_size),\n",
    "            )\n",
    "            \n",
    "        self.head = ArcMarginProduct(self.embedding_size, args.n_classes)\n",
    "        \n",
    "        if args.pretrained_weights is not None:\n",
    "            self.load_state_dict(torch.load(args.pretrained_weights, map_location='cpu'), strict=False)\n",
    "            print('weights loaded from',args.pretrained_weights)\n",
    "\n",
    "    def forward(self, input_dict, get_embeddings=False, get_attentions=False):\n",
    "\n",
    "        x = input_dict['input']\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        x = x[:,:,0,0]\n",
    "        \n",
    "        x = self.neck(x)\n",
    "\n",
    "        logits = self.head(x)\n",
    "\n",
    "        # if not torch.isfinite(logits[0, 0]):\n",
    "        #     print(input_dict['input'], x)\n",
    "        \n",
    "        if get_embeddings:\n",
    "            return {'logits': logits, 'embeddings': x}\n",
    "        else:\n",
    "            return {'logits': logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import *\n",
    "from utils import *\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "import geffnet\n",
    "\n",
    "from loss import *\n",
    "\n",
    "def optimizer_zero_grad(epoch, batch_idx, optimizer, optimizer_idx):\n",
    "    # optimizer.zero_grad()\n",
    "    for param in self.model.parameters():\n",
    "        param.grad = None\n",
    "\n",
    "def train_epoch(metric_crit, epoch, model, loader, optimizer):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    arcface = []\n",
    "    bar = tqdm(loader)\n",
    "    for batch in bar:\n",
    "        batch['input'] = batch['input'].to(args.device)\n",
    "        batch['target'] = batch['target'].to(args.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(batch)\n",
    "        loss = loss_fn(metric_crit, batch, logits)\n",
    "        if not torch.isfinite(loss):\n",
    "            print('WARNING: non-finite loss, ending training ')\n",
    "\n",
    "            print(loss, batch, logits, batch['input'].shape, batch['target'].shape)\n",
    "            exit(1)\n",
    "\n",
    "        if args.arcface_s is None:\n",
    "            s = metric_crit.s.detach().cpu().numpy()\n",
    "        elif args.arcface_s == -1:\n",
    "            s = 0\n",
    "        else:\n",
    "            s = metric_crit.s\n",
    "        \n",
    "        if args.distributed_backend == \"ddp\":\n",
    "            step = epoch*args.batch_size*len(args.gpus.split(','))*args.gradient_accumulation_steps\n",
    "        else:\n",
    "            step = epoch*args.batch_size*args.gradient_accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        arcface.append(s)\n",
    "        \n",
    "        bar.set_description('loss: %.5f, arcface_s: %.5f' % (loss_np, s))\n",
    "    \n",
    "    train_loss = np.mean(train_loss)\n",
    "    arcface = np.mean(arcface)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def get_trans(img, I):\n",
    "    if I >= 4:\n",
    "        img = img.transpose(2,3)\n",
    "    if I % 4 == 0:\n",
    "        return img\n",
    "    elif I % 4 == 1:\n",
    "        return img.flip(2)\n",
    "    elif I % 4 == 2:\n",
    "        return img.flip(3)\n",
    "    elif I % 4 == 3:\n",
    "        return img.flip(2).flip(3)\n",
    "\n",
    "\n",
    "def val_epoch(metric_crit_val, model, loader, n_test=1, get_output=False):\n",
    "    model.eval()\n",
    "    val_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            batch['input'] = batch['input'].to(args.device)\n",
    "            batch['target'] = batch['target'].to(args.device)\n",
    "\n",
    "            output_dict = model(batch, get_embeddings=True)\n",
    "            loss = loss_fn(metric_crit_val, batch, output_dict, val=True)\n",
    "\n",
    "            # temp_batch = batch.copy()\n",
    "            # for I in range(n_test):\n",
    "            #     if I == 0:\n",
    "            #         output_dict = model(temp_batch, get_embeddings=True)\n",
    "            #         logits = output_dict['logits']\n",
    "            #         embeddings = output_dict['embeddings']\n",
    "            #     else:\n",
    "            #         temp_batch['input'] = get_trans(temp_batch['input'], I)\n",
    "            #         output_dict2 = model(temp_batch, get_embeddings=False)\n",
    "            #         logits += output_dict2['logits']\n",
    "            # else:\n",
    "            #     logits /= n_test\n",
    "            #     output_dict['logits'] = logits[0]\n",
    "\n",
    "            # (values, indices) = torch.topk(logits, 3, dim=1)\n",
    "            # preds = indices[:, 0]\n",
    "            # preds_conf = values[:, 0]\n",
    "\n",
    "            logits = output_dict['logits']\n",
    "            embeddings = output_dict['embeddings']\n",
    "\n",
    "            preds_conf, preds = torch.max(logits.softmax(1),1)\n",
    "\n",
    "            # allowed_classes = torch.Tensor(list(range(args.n_classes))).long().to(logits.device)\n",
    "\n",
    "            # preds_conf_pp, preds_pp = torch.max(logits.gather(1,allowed_classes.repeat(logits.size(0),1)).softmax(1),1)\n",
    "            # preds_pp = allowed_classes[preds_pp]\n",
    "\n",
    "            targets = batch['target']\n",
    "\n",
    "            output = dict({\n",
    "                'idx':batch['idx'],\n",
    "                'embeddings': embeddings,\n",
    "                'val_loss': loss.view(1),\n",
    "                # 'val_loss': torch.tensor([0], device='cuda:0'),\n",
    "                'preds': preds,\n",
    "                'preds_conf':preds_conf,\n",
    "                # 'preds_pp': preds_pp,\n",
    "                # 'preds_conf_pp':preds_conf_pp,\n",
    "                'targets': targets,\n",
    "                \n",
    "            })\n",
    "            val_outputs += [output] \n",
    "\n",
    "    return val_outputs\n",
    "\n",
    "def val_end(val_outputs):\n",
    "    out_val = {}\n",
    "    for key in val_outputs[0].keys():\n",
    "        out_val[key] = torch.cat([o[key] for o in val_outputs])\n",
    "\n",
    "    device = out_val[\"targets\"].device\n",
    "\n",
    "    for key in out_val.keys():\n",
    "            out_val[key] = out_val[key].detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    val_score = comp_metric(out_val[\"targets\"], [out_val[\"preds\"], out_val[\"preds_conf\"]])\n",
    "    val_score_landmarks = comp_metric(out_val[\"targets\"], [out_val[\"preds\"], out_val[\"preds_conf\"]])\n",
    "\n",
    "    # val_score_pp = comp_metric(out_val[\"targets\"], [out_val[\"preds_pp\"], out_val[\"preds_conf_pp\"]])\n",
    "    # val_score_landmarks_pp = comp_metric(out_val[\"targets\"], [out_val[\"preds_pp\"], out_val[\"preds_conf_pp\"]])\n",
    "\n",
    "    val_loss_mean = np.sum(out_val[\"val_loss\"])\n",
    "    \n",
    "    results = {'val_loss': val_loss_mean,\n",
    "                     'val_gap':val_score,\n",
    "                     'val_gap_landmarks':val_score_landmarks,\n",
    "                    #  'val_gap_pp':val_score_pp,\n",
    "                    #  'val_gap_landmarks_pp':val_score_landmarks_pp,\n",
    "                    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(args.seed)\n",
    "\n",
    "train = pd.read_csv('../data/public/train.csv')\n",
    "skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "train['fold'] = 0\n",
    "for idx, [trn, val] in enumerate(skf.split(train, train['landmark_id'])):\n",
    "    train.loc[val, 'fold'] = idx\n",
    "train['filepath'] = [os.path.join('../data/train', str(lm_id), str(id)+'.JPG') for lm_id, id in zip(train['landmark_id'], train['id'])]\n",
    "\n",
    "if args.class_weights == \"log\":\n",
    "    val_counts = train.landmark_id.value_counts().sort_index().values\n",
    "    class_weights = 1/np.log1p(val_counts)\n",
    "    class_weights = (class_weights / class_weights.sum()) * args.n_classes\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "else:\n",
    "    class_weights = None\n",
    "\n",
    "trn = train.loc[train['fold']!=args.fold].reset_index(drop=True)\n",
    "val = train.loc[train['fold']==args.fold].reset_index(drop=True)\n",
    "\n",
    "print(f'trn size : {trn.landmark_id.nunique()}, last batch size : {trn.shape[0]%args.batch_size}') #: 1049\n",
    "# print(len(trn)) #: 70481\n",
    "# image size : (540, 960, 3)\n",
    "\n",
    "if args.DEBUG:\n",
    "    trn = trn.iloc[:2500]\n",
    "    val = val.iloc[:2500]\n",
    "\n",
    "train_dataset = LMDataset(trn, aug=args.tr_aug, normalization=args.normalization)\n",
    "valid_dataset = LMDataset(val, aug=args.val_aug, normalization=args.normalization)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False, pin_memory=False)\n",
    "\n",
    "model = Net(args)\n",
    "model = model.to(args.device)\n",
    "\n",
    "# optimizer definition\n",
    "metric_crit = ArcFaceLoss(args.arcface_s, args.arcface_m, crit=args.crit, weight=class_weights)\n",
    "metric_crit_val = ArcFaceLoss(args.arcface_s, args.arcface_m, crit=args.crit, weight=None, reduction=\"sum\")\n",
    "if args.optim=='sgd':\n",
    "    optimizer = torch.optim.SGD([{'params': model.parameters()}, {'params': metric_crit.parameters()}], lr=args.lr, momentum=0.9, nesterov=True, weight_decay=args.weight_decay)\n",
    "elif args.optim=='adamw':\n",
    "    optimizer = torch.optim.AdamW([{'params': model.parameters()}, {'params': metric_crit.parameters()}], lr=args.lr, weight_decay=args.weight_decay, amsgrad=False)\n",
    "\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.cosine_epo)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=args.warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "\n",
    "val_pp = 0.\n",
    "model_file = f'../model/{args.backbone}_best_fold_{args.fold}.pth'\n",
    "for epoch in range(1, args.cosine_epo+args.warmup_epo+1+49):\n",
    "\n",
    "    scheduler_warmup.step(epoch-1)\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "    train_loss = train_epoch(metric_crit, epoch, model, train_loader, optimizer)\n",
    "    if epoch>1:\n",
    "        val_outputs = val_epoch(metric_crit_val, model, valid_loader)\n",
    "        np.save('../submit/val_outputs_best.npy', val_outputs)\n",
    "        results = val_end(val_outputs)\n",
    "        print(results)\n",
    "\n",
    "        val_loss = results['val_loss']\n",
    "        val_gap = results['val_gap']\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {args.fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {val_loss:.5f}, val_gap: {val_gap:.4f}'\n",
    "        print(content)\n",
    "        with open(f'../model/log_fold_{args.backbone}_{args.fold}.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        val_gap_pp = val_gap\n",
    "        if val_gap_pp > val_pp:\n",
    "            print('val_gap_pp_max ({:.6f} --> {:.6f}). Saving model ...'.format(val_pp, val_gap_pp))\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            val_pp = val_gap_pp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('cloud': conda)",
   "language": "python",
   "name": "python37964bitcloudconda2e492f8b7a0c4d89873e0681c6f92d2e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
