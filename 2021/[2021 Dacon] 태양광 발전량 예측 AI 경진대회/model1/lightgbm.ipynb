{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train/train.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "submission['time'] = submission['id'].apply(lambda x: x.split('_')[2].replace('h', '.').replace('m', '')).astype(float)\n",
    "\n",
    "# 4시 30분 이전, 19시 30분 이후는 발전량 0으로 고정\n",
    "zero_idx = submission.loc[(submission['time']<=4.3) | (submission['time']>=19.3)].index\n",
    "submission.drop(columns='time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(day_range=1):\n",
    "    train_list = []\n",
    "    tar_list = []\n",
    "    for day in tqdm(range(day_range-1, int(train.shape[0]/48-2))):\n",
    "        temp = train.loc[(train['Day']<=day) & (train['Day']>day-day_range), ['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET']]\n",
    "        temp2 = []\n",
    "        for col in ['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET']:\n",
    "            temp2 += [temp[col].values.reshape(-1)]\n",
    "        temp = np.concatenate(temp2)\n",
    "        target = train.loc[train['Day']==day+1, 'TARGET'].values.tolist()\n",
    "        target2 = train.loc[train['Day']==day+2, 'TARGET'].values.tolist()\n",
    "        target += target2\n",
    "        train_list += [temp]\n",
    "        tar_list += [target]\n",
    "    train_arr = np.concatenate([train_list], 1)\n",
    "    tar_arr = np.concatenate([tar_list], 1)\n",
    "    print(train_arr.shape, tar_arr.shape)\n",
    "\n",
    "    test_list = []\n",
    "    for i in tqdm(range(81)):\n",
    "        file_path = '../data/test/' + str(i) + '.csv'\n",
    "        temp = pd.read_csv(file_path)\n",
    "        temp2 = []\n",
    "        temp = temp.loc[(temp['Day']<=6) & (temp['Day']>6-day_range), ['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET']]\n",
    "        for col in ['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET']:\n",
    "            temp2 += [temp[col].values.reshape(-1)]\n",
    "        temp = np.concatenate(temp2)\n",
    "        test_list += [temp]\n",
    "    test_arr = np.concatenate([test_list], 1)\n",
    "    print(test_arr.shape)\n",
    "    \n",
    "    return train_arr, tar_arr, test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "total_model = {}\n",
    "\n",
    "for day_range in range(3, 8):\n",
    "    train_arr, tar_arr, test_arr = load(day_range=day_range)\n",
    "\n",
    "    #################### data preprocessing\n",
    "    total_rep = []\n",
    "    for idx in range(train_arr.shape[0]):\n",
    "        rep = []\n",
    "        for i in range(96):\n",
    "            rep += [train_arr[idx, :]]\n",
    "        rep = np.concatenate([rep, np.array([i for i in range(96)]).reshape(-1, 1)], 1)\n",
    "        total_rep += [rep]\n",
    "\n",
    "    train_arr = np.concatenate(total_rep)\n",
    "    tar_arr = tar_arr.reshape(-1)\n",
    "\n",
    "    total_rep = []\n",
    "    for idx in range(test_arr.shape[0]):\n",
    "        rep = []\n",
    "        for i in range(96):\n",
    "            rep += [test_arr[idx, :]]\n",
    "        rep = np.concatenate([rep, np.array([i for i in range(96)]).reshape(-1, 1)], 1)\n",
    "        total_rep += [rep]\n",
    "    test_arr = np.concatenate(total_rep)\n",
    "\n",
    "    print(train_arr.shape, tar_arr.shape, test_arr.shape)\n",
    "\n",
    "    #################### nunique features > 1\n",
    "    not_unique_features = (pd.DataFrame(train_arr).nunique()>1).values\n",
    "    train_arr = train_arr[:, not_unique_features]\n",
    "    test_arr = test_arr[:, not_unique_features]\n",
    "\n",
    "    print(train_arr.shape, tar_arr.shape, test_arr.shape)\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=0, shuffle=False)\n",
    "    splits = [[trn_idx, val_idx] for trn_idx, val_idx in kf.split(train_arr)]\n",
    "    #################### modeling\n",
    "    model_dict = {}\n",
    "    for fold in range(5):\n",
    "        models = []\n",
    "        tr = train_arr[splits[fold][0]]\n",
    "        val = train_arr[splits[fold][1]]\n",
    "\n",
    "        tr_target = tar_arr[splits[fold][0]]\n",
    "        val_target = tar_arr[splits[fold][1]]\n",
    "        \n",
    "        for q in quantiles:\n",
    "            print(f'day_range:{day_range}, fold:{fold}, q:{q}')\n",
    "\n",
    "            lgbm = LGBMRegressor(objective='quantile',\n",
    "                                alpha=q,\n",
    "                                n_estimators=20000, \n",
    "                                max_depth=8,\n",
    "                                learning_rate=0.1, \n",
    "                                subsample=0.5,\n",
    "                                reg_alpha=0.01,\n",
    "                                reg_lambda=0.01,\n",
    "                                random_state=0,\n",
    "                                n_jobs=8)\n",
    "\n",
    "            lgbm.fit(tr, tr_target, eval_metric = ['quantile'], \n",
    "                                    eval_set=[(tr, tr_target), (val, val_target)], early_stopping_rounds=200, verbose=5000)\n",
    "            \n",
    "            importance_features = lgbm.feature_importances_>1\n",
    "            # importance_features = np.argsort(lgbm.feature_importances_)[::-1][:200]\n",
    "            print(sum(importance_features))\n",
    "            lgbm.fit(tr[:, importance_features], tr_target, eval_metric = ['quantile'], \n",
    "                                    eval_set=[(tr[:, importance_features], tr_target), (val[:, importance_features], val_target)], early_stopping_rounds=200, verbose=1000)\n",
    "\n",
    "            models += [lgbm, importance_features]\n",
    "            print('\\n')\n",
    "            \n",
    "        model_dict[fold] = models\n",
    "    total_model[day_range] = model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../submit/model/lgb_models.npy', total_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_model = np.load('../submit/model/lgb_models.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_quantile_preds = {}\n",
    "s_day_quantile_preds = {}\n",
    "\n",
    "for day_range in range(3, 8):\n",
    "    train_arr, tar_arr, test_arr = load(day_range=day_range)\n",
    "\n",
    "    #################### data preprocessing\n",
    "    total_rep = []\n",
    "    for idx in range(train_arr.shape[0]):\n",
    "        rep = []\n",
    "        for i in range(96):\n",
    "            rep += [train_arr[idx, :]]\n",
    "        rep = np.concatenate([rep, np.array([i for i in range(96)]).reshape(-1, 1)], 1)\n",
    "        total_rep += [rep]\n",
    "\n",
    "    train_arr = np.concatenate(total_rep)\n",
    "    tar_arr = tar_arr.reshape(-1)\n",
    "\n",
    "    total_rep = []\n",
    "    for idx in range(test_arr.shape[0]):\n",
    "        rep = []\n",
    "        for i in range(96):\n",
    "            rep += [test_arr[idx, :]]\n",
    "        rep = np.concatenate([rep, np.array([i for i in range(96)]).reshape(-1, 1)], 1)\n",
    "        total_rep += [rep]\n",
    "    test_arr = np.concatenate(total_rep)\n",
    "\n",
    "    print(train_arr.shape, tar_arr.shape, test_arr.shape)\n",
    "\n",
    "    #################### nunique features > 1\n",
    "    not_unique_features = (pd.DataFrame(train_arr).nunique()>1).values\n",
    "    train_arr = train_arr[:, not_unique_features]\n",
    "    test_arr = test_arr[:, not_unique_features]\n",
    "    print(train_arr.shape, tar_arr.shape, test_arr.shape)\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=0, shuffle=False)\n",
    "    splits = [[trn_idx, val_idx] for trn_idx, val_idx in kf.split(train_arr)]\n",
    "    \n",
    "    s_fold_quantile_preds = np.zeros([len(test_arr), 9])\n",
    "    for fold in range(5):\n",
    "        s_quantile_preds = []\n",
    "        print(f'day_range:{day_range}, fold:{fold}')\n",
    "        for i, q in enumerate(quantiles):\n",
    "            model = total_model[day_range][fold][i*2]\n",
    "            importance_features = total_model[day_range][fold][i*2+1]\n",
    "            s_quantile_preds += [model.predict(test_arr[:,importance_features])]\n",
    "        print('\\n')\n",
    "        s_fold_quantile_preds += np.concatenate([s_quantile_preds], 1).T/5\n",
    "    s_day_quantile_preds[day_range] = s_fold_quantile_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:, 1:] = np.mean([s_day_quantile_preds[3], s_day_quantile_preds[4], s_day_quantile_preds[5], s_day_quantile_preds[6], s_day_quantile_preds[7]], 0).round(2)\n",
    "submission.loc[zero_idx, 'q_0.1':]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../submit/lgb_model.csv', index=False)"
   ]
  }
 ]
}