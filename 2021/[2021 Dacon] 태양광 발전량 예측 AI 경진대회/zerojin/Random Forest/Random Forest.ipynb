{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MO_RF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ShvulFEa1oP"
      },
      "source": [
        "# 구글드라이브 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GELgAYoaatWt",
        "outputId": "6a63821b-af1e-45bc-ccc8-c779b0a79942"
      },
      "source": [
        "# google drive와 colab연동\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ1aUfrlbJMi"
      },
      "source": [
        "# 함수 호출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iG0H60KbKUK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from math import cos,radians\n",
        "from collections import Counter \n",
        "from tqdm import tqdm\n",
        "from sklearn import ensemble\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcNUkiFxa4vR"
      },
      "source": [
        "# 데이터 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPIn4tmMa3A6",
        "outputId": "6b8931b0-48c2-4b80-813e-8d3dee63c365"
      },
      "source": [
        "path = \"./gdrive/My Drive/dacon/발전량/data/\"\n",
        "\n",
        "train_df = pd.read_csv(path+'./train/train.csv')\n",
        "sub_df = pd.read_csv(path+'./sample_submission.csv')\n",
        "\n",
        "test_df = pd.DataFrame()\n",
        "\n",
        "for i in tqdm(os.listdir(path+'./test/')):\n",
        "    df = pd.read_csv(path+\"./test/\"+i)\n",
        "    df[\"F_NAME\"] = \"TEST_\"+i\n",
        "    test_df = pd.concat([test_df,df],axis=0)\n",
        "    del df\n",
        "\n",
        "test_df[\"TY\"] = test_df[\"F_NAME\"].apply(lambda x:x[x.find(\"_\")+1:x.find(\".\")])\n",
        "test_df[\"TY\"] = test_df[\"TY\"].astype('int')\n",
        "test_df.sort_values(by=[\"TY\",\"Day\",\"Hour\",\"Minute\"],inplace=True)\n",
        "test_df = test_df.reset_index(drop=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:22<00:00,  3.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCq_ceSfbYjE"
      },
      "source": [
        "# FE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtkZOTF7bSTC"
      },
      "source": [
        "def sun_check(df):\n",
        "    que = 0\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "\n",
        "        if (df[\"DHI\"][i]>0) & (df[\"DHI\"][i]>0):\n",
        "            que = 1\n",
        "\n",
        "        elif (df[\"DHI\"][i] ==0) & (df[\"DHI\"][i]==0):\n",
        "            que = 0\n",
        "\n",
        "        df.loc[i,\"sun_check\"] = que \n",
        "        \n",
        "    df[\"sun_check\"] = df[\"sun_check\"].astype('int')\n",
        "    \n",
        "    return df\n",
        "    \n",
        "def Altitude_check(cc):\n",
        "    \n",
        "    up_unit = round((69-45) / (cc.loc[:cc[cc['Altitude']==69].index[0],'Altitude'].isnull().sum()),2)\n",
        "    down_unit = round((69-45) / (cc.loc[cc[cc['Altitude']==69].index[0]:,'Altitude'].isnull().sum()),2)\n",
        "\n",
        "    que = 0\n",
        "\n",
        "    for i in range(1,len(cc)-1):\n",
        "        if (cc['Altitude'][i-1] == 0) & np.isnan(cc['Altitude'][i]) & (que == 0):\n",
        "            cc.loc[i,'Altitude'] = 45\n",
        "            que = 1\n",
        "\n",
        "        elif (cc['Altitude'][i-1] >= 45) & np.isnan(cc['Altitude'][i]) & (que == 1):\n",
        "            cc.loc[i,'Altitude'] = cc['Altitude'][i-1] + up_unit\n",
        "\n",
        "        elif (cc['Altitude'][i] == 69) & (cc['Altitude'][i] >= 0):\n",
        "            que = 2 \n",
        "            continue\n",
        "            \n",
        "        elif (cc['Altitude'][i-1] <= 69) & np.isnan(cc['Altitude'][i]) & (que == 2) & (cc['Altitude'][i+1] == 0) :\n",
        "            cc.loc[i,'Altitude'] = 45\n",
        "        \n",
        "        elif (cc['Altitude'][i-1] <= 69) & np.isnan(cc['Altitude'][i]) & (que == 2):\n",
        "            cc.loc[i,'Altitude'] = cc['Altitude'][i-1] - down_unit\n",
        "            \n",
        "    return cc\n",
        "    \n",
        "\n",
        "def Altitude(df,train=True):\n",
        "    \n",
        "    if train == True:\n",
        "        df = sun_check(df)\n",
        "        \n",
        "        all_df = pd.DataFrame()\n",
        "\n",
        "        df.loc[(df[\"Hour\"]==12) & (df[\"Minute\"]==30),\"Altitude\"] = 69\n",
        "        df.loc[(df[\"sun_check\"]==0),\"Altitude\"] = 0\n",
        "\n",
        "        for i in df[\"Day\"].unique():\n",
        "            cc_fe = Altitude_check(df[df['Day']==i].reset_index(drop=True))\n",
        "            all_df = pd.concat([all_df,cc_fe],axis=0).reset_index(drop=True)\n",
        "            \n",
        "        all_df['Altitude_diff'] = 90 - all_df['Altitude']\n",
        "        all_df.loc[all_df['Altitude_diff']==90,\"Altitude_diff\"]=0\n",
        "        all_df['GHI'] = all_df['DHI'] + (all_df['DNI'] *[cos(radians(i)) for i in all_df['Altitude_diff'].values])\n",
        "\n",
        "        return all_df\n",
        "\n",
        "    else:\n",
        "        df = sun_check(df)\n",
        "        all_df = pd.DataFrame()\n",
        "\n",
        "        df.loc[(df[\"Hour\"]==12) & (df[\"Minute\"]==30),\"Altitude\"] = 69\n",
        "        df.loc[(df[\"sun_check\"]==0),\"Altitude\"] = 0\n",
        "        \n",
        "        for i in test_df_fe[\"TY\"].unique():\n",
        "            temp = test_df_fe[test_df_fe[\"TY\"]==i].reset_index(drop=True)\n",
        "\n",
        "            for j in temp[\"Day\"].unique():\n",
        "                cc_fe = Altitude_check(temp[temp['Day'] == j].reset_index(drop=True))\n",
        "                all_df = pd.concat([all_df,cc_fe],axis=0).reset_index(drop=True)\n",
        "        \n",
        "        all_df['Altitude_diff'] = 90 - all_df['Altitude']\n",
        "        all_df.loc[all_df['Altitude_diff']==90,\"Altitude_diff\"]=0\n",
        "        all_df['GHI'] = all_df['DHI'] + (all_df['DNI'] *[cos(radians(i)) for i in all_df['Altitude_diff'].values])\n",
        "        \n",
        "        return all_df\n",
        "\n",
        "def time_all(df):\n",
        "    set_df = df.copy()\n",
        "\n",
        "    # 변수 만들기 끝\n",
        "    set_df[\"ALL_TIME\"] = set_df[\"Hour\"]*60 + set_df[\"Minute\"]\n",
        "    set_df[\"ALL_TIME\"] = set_df[\"ALL_TIME\"].astype('category')\n",
        "\n",
        "    return set_df\n",
        "\n",
        "def time_m(df):\n",
        "\n",
        "    m1 = [1,2,3,4,5,6]\n",
        "    m2 = [7,8,9,10,11,12]\n",
        "    m3 = [13,14,15,16,17,18]\n",
        "    m4 = [19,20,21,22,23,0]\n",
        "\n",
        "    df.loc[df[\"Hour\"].isin(m1),\"M_GROUP\"] = 1\n",
        "    df.loc[df[\"Hour\"].isin(m2),\"M_GROUP\"] = 2\n",
        "    df.loc[df[\"Hour\"].isin(m3),\"M_GROUP\"] = 3\n",
        "    df.loc[df[\"Hour\"].isin(m4),\"M_GROUP\"] = 4\n",
        "\n",
        "    df[\"M_GROUP\"] = df[\"M_GROUP\"].astype('category')\n",
        "\n",
        "    return df\n",
        "\n",
        "def dark(df):\n",
        "    df.loc[df['TARGET']==0,'DARK'] = 1\n",
        "    df.loc[df['TARGET']!=0,'DARK'] = 0\n",
        "    \n",
        "    df['DARK'] = df['DARK'].astype('category')\n",
        "    \n",
        "    return df\n",
        "\n",
        "def time_function(train_df,test_df):\n",
        "\n",
        "    train_df_fe = time_all(train_df)\n",
        "    test_df_fe = time_all(test_df)\n",
        "\n",
        "    train_df_fe = time_m(train_df_fe)\n",
        "    test_df_fe = time_m(test_df_fe)\n",
        "    \n",
        "    train_df_fe = dark(train_df_fe)\n",
        "    test_df_fe = dark(test_df_fe)\n",
        "    \n",
        "    train_df_fe['DARK'] = train_df_fe['DARK'].astype('category') \n",
        "    test_df_fe['DARK'] = test_df_fe['DARK'].astype('category') \n",
        "    \n",
        "    return train_df_fe, test_df_fe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6hfAjVbeox"
      },
      "source": [
        "# 새로운 데이터 셋\n",
        "train_df_fe,test_df_fe = time_function(train_df,test_df)\n",
        "\n",
        "train_df_fe = Altitude(train_df_fe,train=True)\n",
        "test_df_fe = Altitude(test_df_fe,train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa2IB8S-fjMA"
      },
      "source": [
        "# slide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujITcqozbsFo"
      },
      "source": [
        "def transform(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step):\n",
        "    data = []\n",
        "    labels = []\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "    for i in range(start_index, end_index, 48):\n",
        "        indices = range(i-history_size, i, step)\n",
        "        data.append(np.ravel(dataset[indices].T))\n",
        "        labels.append(target[i:i+target_size])\n",
        "    data = np.array(data)\n",
        "    labels = np.array(labels)\n",
        "    return data, labels\n",
        "\n",
        "duse_col = ['Day','Hour','Minute','DARK','sun_check','Altitude_diff','Altitude']\n",
        "x_col = [i for i in train_df_fe if i not in duse_col]\n",
        "y_col = ['TARGET']\n",
        "\n",
        "dataset = train_df_fe.loc[:,x_col].values\n",
        "label = np.ravel(train_df_fe.loc[:,y_col].values)\n",
        "\n",
        "past_history = 48 * 7\n",
        "future_target = 48 * 2\n",
        "\n",
        "### transform train\n",
        "train_data, train_label = transform(dataset, label, 0,None, past_history,future_target, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWHUnTXu3_nK",
        "outputId": "5088a51e-92a5-4b24-a1b4-21288c3ddaa2"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1086, 3024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLkYodTn1Mr4"
      },
      "source": [
        "test = []\n",
        "\n",
        "for i in range(81):\n",
        "    data = []\n",
        "    tmp = test_df_fe[test_df_fe['TY'] == i].reset_index(drop=True)\n",
        "    tmp = tmp.loc[:, x_col].values\n",
        "    tmp = tmp[-past_history:,:]\n",
        "    data.append(np.ravel(tmp.T))\n",
        "    data = np.array(data)\n",
        "    test.append(data)\n",
        "\n",
        "test = np.concatenate(test, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maep0MhpzHmu",
        "outputId": "dab3341e-0e14-4fd6-9363-0cd2a4395531"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "for i,(train_index, valid_index) in enumerate(kf.split(train_data)):\n",
        "  print(i+1,'번째 fold 학습 진행')\n",
        "\n",
        "  train_x = train_data[train_index]\n",
        "  train_y = train_label[train_index]\n",
        "\n",
        "  valid_x = train_data[valid_index]\n",
        "  valid_y = train_label[valid_index]\n",
        "\n",
        "  rf = ensemble.RandomForestRegressor(n_estimators=1000, criterion='mae',\n",
        "                                    max_features = 10, random_state=42,\n",
        "                                    max_depth = 10,\n",
        "                                    verbose=False,\n",
        "                                    n_jobs=-1)\n",
        "\n",
        "  rf.fit(train_x, train_y)\n",
        "  print(rf.score(valid_x,valid_y))\n",
        "\n",
        "  rf_preds = []\n",
        "\n",
        "  for estimator in rf.estimators_:\n",
        "      rf_preds.append(estimator.predict(test))\n",
        "  rf_preds = np.array(rf_preds)\n",
        "\n",
        "  for i, q in enumerate(np.arange(0.1, 1, 0.1)):\n",
        "      y_pred = np.percentile(rf_preds, q * 100, axis=0)\n",
        "      sub_df.iloc[:, i+1] = np.ravel(y_pred)/5    \n",
        "  print('학습 끝 \\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 번째 fold 학습 진행\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.21501261745140354\n",
            "학습 끝 \n",
            "\n",
            "2 번째 fold 학습 진행\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.39498510321801866\n",
            "학습 끝 \n",
            "\n",
            "3 번째 fold 학습 진행\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.08636917702654279\n",
            "학습 끝 \n",
            "\n",
            "4 번째 fold 학습 진행\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.4024460952248175\n",
            "학습 끝 \n",
            "\n",
            "5 번째 fold 학습 진행\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.3070902877577591\n",
            "학습 끝 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kBjOIbJiQFu"
      },
      "source": [
        "sub_df = pd.read_csv(path+'./sample_submission.csv')\n",
        "\n",
        "for i, q in enumerate(np.arange(0.1, 1, 0.1)):\n",
        "    y_pred = np.percentile(rf_preds, q * 100, axis=0)\n",
        "    sub_df.iloc[:, i+1] = np.ravel(y_pred)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHJ_goMaiQIc"
      },
      "source": [
        "sub_df.to_csv(path+'ranfo_q_ver1.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}