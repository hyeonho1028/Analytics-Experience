{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"real_day.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"c8mSSO7VKAjW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":829},"outputId":"9168a00d-7440-401e-9324-c7f7b7b96659","executionInfo":{"status":"ok","timestamp":1572054826887,"user_tz":-540,"elapsed":33291,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import gc\n","import tqdm\n","import datetime\n","import random\n","from collections import defaultdict\n","from sklearn.neural_network import MLPRegressor\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import Lasso, Ridge\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit, GroupKFold\n","from sklearn.svm import SVR\n","\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# model\n","import xgboost as xgb\n","import lightgbm as lgb\n","\n","# evaluation\n","from sklearn.metrics import mean_squared_error\n","\n","# install\n","!pip install workalendar\n","from workalendar.asia import SouthKorea"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Collecting workalendar\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/3b/0674dab5f7b9878c4907ad9f833575fc23c58616c126c65cd21b9fd2bedb/workalendar-7.0.0-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 5.1MB/s \n","\u001b[?25hRequirement already satisfied: lunardate in /usr/local/lib/python3.6/dist-packages (from workalendar) (0.2.0)\n","Collecting skyfield\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9c/4a9879460dddac5bda8d7e8b8eb6159093d2b285077d085ff78d4f02a2bc/skyfield-1.13.tar.gz (224kB)\n","\u001b[K     |████████████████████████████████| 225kB 39.8MB/s \n","\u001b[?25hCollecting pyCalverter\n","  Downloading https://files.pythonhosted.org/packages/4f/5c/57c6853f7a5bc41fc9da7651ae67b9c76381083742613faa7381724081e9/pyCalverter-1.6.1.tar.gz\n","Collecting pyluach\n","  Downloading https://files.pythonhosted.org/packages/79/2c/4f413270a621dd6238fa67d9db81efd5edc02b44a5b1b8510552f643fc58/pyluach-1.0.1-py3-none-any.whl\n","Collecting skyfield-data\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/46/666a4b44709badf6e11b8b77a7aeefebababc1648f46a893f9f8642e99b3/skyfield_data-0.1.0-py2.py3-none-any.whl (16.0MB)\n","\u001b[K     |████████████████████████████████| 16.0MB 156kB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=1.0 in /usr/local/lib/python3.6/dist-packages (from workalendar) (41.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from workalendar) (2.6.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from workalendar) (2018.9)\n","Collecting jplephem>=2.3\n","  Downloading https://files.pythonhosted.org/packages/14/6f/354fd50e625a66c7be3f08095c0e1fa389c75453858acf2689ffa9c4fc54/jplephem-2.9.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from skyfield->workalendar) (1.17.3)\n","Collecting sgp4>=1.4\n","  Downloading https://files.pythonhosted.org/packages/d2/00/3f3699203176017211a71fe16e3fa71bae946ac92ade77d5a2ffc5da8576/sgp4-1.4.tar.gz\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->workalendar) (1.12.0)\n","Building wheels for collected packages: skyfield, pyCalverter, jplephem, sgp4\n","  Building wheel for skyfield (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for skyfield: filename=skyfield-1.13-cp36-none-any.whl size=253163 sha256=c0045bf653e705f853ab95aace86e094900a8595fb8d64f4748d1681e9689210\n","  Stored in directory: /root/.cache/pip/wheels/76/3d/1c/afe30b6c7a526ba23b63c1947c64cc7b9142a6e78858fe2384\n","  Building wheel for pyCalverter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyCalverter: filename=pyCalverter-1.6.1-cp36-none-any.whl size=4200 sha256=8ec8237fbe10621537945bda35012c4f69cf9926a960083cca4ed3b8c50540db\n","  Stored in directory: /root/.cache/pip/wheels/77/4d/86/db4ff4eca6178dbbd5a365d095f97f6021e2a48f09908be79c\n","  Building wheel for jplephem (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jplephem: filename=jplephem-2.9-cp36-none-any.whl size=41100 sha256=3e95b4fca9d881031aaf77690179da9c9e40fb997ed7ef44743354b25f1df094\n","  Stored in directory: /root/.cache/pip/wheels/13/d3/06/3799163edac5d1f454832143f7730413dcc56f42acfbb9f0d3\n","  Building wheel for sgp4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgp4: filename=sgp4-1.4-cp36-none-any.whl size=35410 sha256=3a5f4ccf9acf8582f5801309dfb740afbd04f20f64cd606b6b2f220f1a987ae0\n","  Stored in directory: /root/.cache/pip/wheels/6d/e2/42/5dc20daf2ba62ae03dc8abe10744ee67d9452df447dac561db\n","Successfully built skyfield pyCalverter jplephem sgp4\n","Installing collected packages: jplephem, sgp4, skyfield, pyCalverter, pyluach, skyfield-data, workalendar\n","Successfully installed jplephem-2.9 pyCalverter-1.6.1 pyluach-1.0.1 sgp4-1.4 skyfield-1.13 skyfield-data-0.1.0 workalendar-7.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fMeuiosGKDcD","colab_type":"code","colab":{}},"source":["path = 'drive/My Drive/11dacon/data/'\n","\n","def seed_everything(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    \n","from numba import jit\n","import math\n","\n","@jit\n","def smape_fast(y_true, y_pred, exp=False):\n","    \n","    if exp:\n","        y_true = np.expm1(np.array(y_true))\n","        y_pred = np.expm1(np.array(y_pred))\n","    else:\n","        y_true = np.array(y_true)\n","        y_pred = np.array(y_pred)\n","        \n","    out = 0\n","    for i in range(y_true.shape[0]):\n","        a = y_true[i]\n","        b = y_pred[i]\n","        c = a+b\n","        if c == 0:\n","            continue\n","        out += math.fabs(a - b) / c\n","    out *= (200.0 / y_true.shape[0])\n","    return out\n","\n","def rmse(y_true, y_pred, exp=False):\n","    if exp:\n","        return np.sqrt(mean_squared_error(np.expm1(y_true), np.expm1(y_pred)))\n","    else:\n","        return np.sqrt(mean_squared_error(y_true, y_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DcDxt9N7KDfR","colab_type":"code","colab":{}},"source":["test = pd.read_csv(path+'test.csv')\n","sub = pd.read_csv(path+'submission.csv')\n","\n","holidays = pd.concat([pd.Series(np.array(SouthKorea().holidays(2018))[:, 0]), pd.Series(np.array(SouthKorea().holidays(2017))[:, 0]), pd.Series(np.array(SouthKorea().holidays(2016))[:, 0])]).reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fly2pQ5yWti2","colab_type":"code","colab":{}},"source":["weather = pd.read_csv(path+'weather_day.csv', encoding='cp949').iloc[:, 1:]\n","weather.columns = ['date', '평균기온', '최저기온', '최고기온']\n","weather['date'] = pd.to_datetime(weather['date'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tp_rXSVWKDiM","colab_type":"code","colab":{}},"source":["def merge(train, col):\n","    temp = train[['Time', col]].rename(columns={col:'target'})\n","    temp['Time'] = pd.to_datetime(temp['Time'])\n","    temp = temp[temp['Time']>='2017-11-23'].reset_index(drop=True)\n","    \n","    temp['date'] = pd.to_datetime(temp['Time'].dt.date)\n","    temp = temp.groupby('date')['target'].sum().reset_index()\n","    temp['Time'] = pd.to_datetime(temp['date'].dt.date)\n","    temp = temp[temp['target']>0].reset_index(drop=True)\n","    temp = temp[(temp['target']>temp['target'].mean() - 3*temp['target'].std()) & (temp['target']<temp['target'].mean() + 3*temp['target'].std())]\n","    \n","    \n","    temp['Time'] = pd.to_datetime(temp['Time'])\n","    temp['month'] = temp['Time'].dt.month\n","    temp['week'] = temp['Time'].dt.week\n","    temp['weekday'] = temp['Time'].dt.weekday\n","    temp['day'] = temp['Time'].dt.day\n","    temp['hour'] = temp['Time'].dt.hour\n","    temp['holiday'] = temp['Time'].dt.date.isin(holidays).astype(int)\n","    temp['weekend'] = temp['weekday'].map({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:1})\n","    temp['is_holiday'] = (temp['weekend'] + temp['holiday']).map({0:0, 1:1, 2:1})\n","    \n","\n","    \n","    temp2 = pd.DataFrame(pd.date_range('20180701', '20181201', freq='h'), columns=['Time']).iloc[:-1, :]\n","    temp2['Time'] = pd.to_datetime(temp2['Time'])\n","    temp2['month'] = temp2['Time'].dt.month\n","    temp2['week'] = temp2['Time'].dt.week\n","    temp2['weekday'] = temp2['Time'].dt.weekday\n","    temp2['day'] = temp2['Time'].dt.day\n","    temp2['hour'] = temp2['Time'].dt.hour\n","    temp2['holiday'] = temp2['Time'].dt.date.isin(holidays).astype(int)\n","    temp2['weekend'] = temp2['weekday'].map({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:1})\n","    temp2['is_holiday'] = (temp2['weekend'] + temp2['holiday']).map({0:0, 1:1, 2:1})\n","    \n","    temp = pd.merge(temp, weather, how='left', on='date')\n","    \n","    return temp, temp2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_uBAiKgzZ3P","colab_type":"code","colab":{}},"source":["test_df = train_df.iloc[-10:]\n","train_df = train_df.iloc[:-10]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLhqhjlI3W2Q","colab_type":"code","colab":{}},"source":["from statsmodels.tsa.arima_model import ARIMA # ARIMA 모델\n","import itertools\n","\n","import statsmodels.formula.api as smf            # statistics and econometrics\n","import statsmodels.tsa.api as smt\n","import statsmodels.api as sm\n","import scipy.stats as scs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zINjh6E4L-t","colab_type":"code","colab":{}},"source":["p = d = q = range(0, 2)\n","pdq = list(itertools.product(p, d, q))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_RnpldM4MD5","colab_type":"code","colab":{}},"source":["# setting initial values and some bounds for them\n","ps = range(2, 5)\n","d=1 \n","qs = range(2, 5)\n","Ps = range(0, 2)\n","D=1 \n","Qs = range(0, 2)\n","s = 24 # season length is still 24\n","\n","# creating list with all the possible combinations of parameters\n","parameters = itertools.product(ps, qs, Ps, Qs)\n","parameters_list = list(parameters)\n","len(parameters_list)\n","\n","def optimizeSARIMA(parameters_list, d, D, s):\n","    \"\"\"\n","        Return dataframe with parameters and corresponding AIC\n","        \n","        parameters_list - list with (p, q, P, Q) tuples\n","        d - integration order in ARIMA model\n","        D - seasonal integration order \n","        s - length of season\n","    \"\"\"\n","    \n","    results = []\n","    best_aic = float(\"inf\")\n","\n","    for param in tqdm.tqdm_notebook(parameters_list):\n","        # we need try-except because on some combinations model fails to converge\n","        try:\n","            model=sm.tsa.statespace.SARIMAX(train_df['target'], order=(param[0], d, param[1]), \n","                                            seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)\n","        except:\n","            continue\n","        aic = model.aic\n","        # saving best model, AIC and parameters\n","        if aic < best_aic:\n","            best_model = model\n","            best_aic = aic\n","            best_param = param\n","        results.append([param, model.aic])\n","\n","    result_table = pd.DataFrame(results)\n","    result_table.columns = ['parameters', 'aic']\n","    # sorting in ascending order, the lower AIC is - the better\n","    result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)\n","    \n","    return result_table"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ByMqU5rF6PM8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":647},"outputId":"fa0f397e-4474-40e5-8e56-f984689ae823","executionInfo":{"status":"ok","timestamp":1572057823353,"user_tz":-540,"elapsed":70292,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}}},"source":["result_table = optimizeSARIMA(parameters_list, d, D, s)\n","# set the parameters that give the lowest AIC\n","p, q, P, Q = result_table.parameters[0]\n","\n","best_model=sm.tsa.statespace.SARIMAX(train_df['target'], order=(p, d, q), \n","                                        seasonal_order=(P, D, Q, s)).fit(disp=-1)\n","forecast = best_model.predict(start = train_df.shape[0], end = train_df.shape[0]+10)\n","forecast"],"execution_count":117,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf8f0e5ed27f453ea3762d372c5d1b25","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/sarimax.py:949: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n","  warn('Non-stationary starting autoregressive parameters'\n","/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/sarimax.py:961: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n","  warn('Non-invertible starting MA parameters found.'\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n","  \"Check mle_retvals\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["63    140.325901\n","64    146.477015\n","65    146.203582\n","66    145.113623\n","67    149.838902\n","68    144.489140\n","69    143.666079\n","70    145.441570\n","71    148.451993\n","72    145.544554\n","73    143.735728\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"id":"che1_AH-762o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"eea6ca16-c35f-4e34-f4e5-86eac45c0579","executionInfo":{"status":"ok","timestamp":1572057823354,"user_tz":-540,"elapsed":67975,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}}},"source":["test_df.target"],"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["63    139.486\n","64    144.542\n","65    147.105\n","66    151.940\n","67    154.992\n","68    147.142\n","69    146.831\n","70    146.159\n","71    152.207\n","72    154.966\n","Name: target, dtype: float64"]},"metadata":{"tags":[]},"execution_count":118}]},{"cell_type":"code","metadata":{"id":"UldZ7Yw77Skg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTJJjXzp4drJ","colab_type":"code","colab":{}},"source":["model = ARIMA(train_df['target'], order=get_optimal_params(train_df['target']))\n","results_ARIMA = model.fit(disp=-1)\n","results_ARIMA.forecast(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1yO_L4d4MIk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EdBRdCVV4MOB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFOJ9Sez4MTz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qFnGRXXV3W7W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-ndA3bSK3Vk","colab_type":"code","outputId":"9942b2b5-574e-4ae0-9807-a20776fee857","executionInfo":{"status":"error","timestamp":1572057584237,"user_tz":-540,"elapsed":664,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":412}},"source":["SEED=42\n","seed_everything(SEED)\n","\n","params = {\n","    'objective':'regression',\n","    'boosting_type':'gbdt',\n","    'metric':'rmse',\n","    'n_jobs':-1,\n","    'learning_rate':0.03,\n","    'num_leaves': 2**9,\n","    'max_depth':-1,\n","    'tree_learner':'serial',\n","    'min_child_weight':5, \n","    'subsample':0.7,\n","    'reg_alpha':0.1,\n","    'reg_lambda':0.1,\n","    'verbose':-1,\n","    'seed': SEED\n","}\n","    \n","rmse_list = []\n","smape_list = []\n","submit_dict = defaultdict()\n","\n","target_arr = np.array([])\n","oof_arr = np.array([])\n","\n","mode = 'test'\n","if mode=='validation':\n","    val_oof = np.zeros(len(valid_df))\n","    val_target = np.array([])\n","    val_oof_list = np.array([])\n","\n","    val_rmse_list = []\n","    val_smape_list = []\n","\n","\n","for idx in tqdm.tqdm_notebook(list(range(200))):\n","    train_df, test_df = merge(test, sub['meter_id'][idx])\n","    \n","    if mode=='validation':\n","        valid_df = train_df.iloc[-24:]\n","        train_df = train_df.iloc[:-24]\n","    \n","    oof = np.zeros(len(train_df))\n","    pred = np.zeros(len(test_df))\n","    \n","    feature = [i for i in train_df.columns if i not in ['target', 'Time', 'weekend', 'holiday', 'date']]\n","    feature = [i for i in feature if 'diff' not in i]\n","    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","    if idx==1:\n","        break\n","\n","    for trn_idx, val_idx in kf.split(train_df):\n","        tt = lgb.Dataset(train_df.loc[trn_idx, feature], train_df.loc[trn_idx, ['target']])\n","        vv = lgb.Dataset(train_df.loc[val_idx, feature], train_df.loc[val_idx, ['target']])\n","\n","        model = lgb.train(params, tt, valid_sets=[tt, vv], early_stopping_rounds=50, verbose_eval=0)\n","#         model = SVR(degree=3, coef0=0.001, kernel='rbf', gamma='auto').fit(train_df.loc[trn_idx, feature], train_df.loc[trn_idx, 'target'])\n","#         model = RandomForestRegressor(n_estimators=100, random_state=42).fit(train_df.loc[trn_idx, feature], train_df.loc[trn_idx, 'target'])\n","\n","        oof[val_idx] = model.predict(train_df.loc[val_idx, feature])\n","        pred += model.predict(test_df[feature])/5\n","    \n","        if mode=='validation':\n","            val_oof += model.predict(valid_df[feature])/5\n","    \n","    if mode=='validation':\n","        val_target = np.concatenate([val_target, valid_df['target'].values])\n","        val_oof_list = np.concatenate([val_oof_list, val_oof])\n","        print(idx, smape_fast(val_target, val_oof_list), rmse(val_target, val_oof_list))\n","        \n","        val_rmse_list.append(rmse(val_target, val_oof_list))\n","        val_smape_list.append(smape_fast(val_target, val_oof_list))\n","    \n","    oof[oof<0] = train_df['target'].min()\n","    pred[pred<0] = train_df['target'].min()\n","#     oof[oof<0] = 0\n","#     pred[pred<0] = 0\n","    \n","    target_arr = np.concatenate([target_arr, train_df['target'].values])\n","    oof_arr = np.concatenate([oof_arr, oof])\n","    print(idx, smape_fast(target_arr, oof_arr), rmse(target_arr, oof_arr), smape_fast(train_df['target'], oof), rmse(train_df['target'], oof))\n","    \n","    # 할당\n","    rmse_list.append(rmse(train_df['target'], oof))\n","    smape_list.append(smape_fast(train_df['target'], oof))\n","    submit_dict[idx] = pred"],"execution_count":112,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cab6a8f0ef14794938c79e805f497f1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-112-02d1f0e891d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['최저기온', '최고기온', '평균기온'] not in index\""]}]},{"cell_type":"code","metadata":{"id":"WkDSzAIRMPLk","colab_type":"code","colab":{}},"source":["rf: 199 193.91180678719994 122.26467220592971\n","lgb : 199 193.8824586822974 118.74868605407516"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RTsEthrzqDGa","colab_type":"code","outputId":"af985d6d-243a-42c6-a576-bcec0e64b62c","executionInfo":{"status":"ok","timestamp":1572019386016,"user_tz":-540,"elapsed":742,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.mean(rmse_list), np.mean(smape_list)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.2660960687585986, 29.514586692448574)"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"tfnAaijyO4rT","colab_type":"code","outputId":"3da5e0c5-ef16-49f3-ae63-b568a934501b","executionInfo":{"status":"ok","timestamp":1572016294393,"user_tz":-540,"elapsed":574,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.mean(rmse_list), np.mean(smape_list)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.2715865953678639, 29.698993530910787)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"GYNg2bLYKDus","colab_type":"code","colab":{}},"source":["submit_df = pd.concat([pd.DataFrame(submit_dict).loc[:23], \n","                       pd.concat([pd.DataFrame([j for i in range(10) for j in str(i) * 24], columns=['house']), pd.DataFrame(submit_dict).loc[:239]], 1).groupby('house').sum().reset_index(drop=True),\n","                       pd.concat([test_df['Time'].dt.to_period('m'), pd.DataFrame(submit_dict)], 1).groupby('Time').sum().reset_index(drop=True)])\n","\n","submit_df.columns = sub['meter_id']\n","submit_df = submit_df.T.reset_index()\n","submit_df.columns = sub.columns\n","submit_df.head(15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E_Yb3eXky7w","colab_type":"code","colab":{}},"source":["-----------------------------------------------------------------\n","month, day, week, weekday, hour 만 사용\n","\n","nan process -> 3sigma\n","mean : (0.2678278947214462, 29.149798158558028)\n","LB : 29.8\n","\n","+ is_holiday => 광한\n","mean : (0.2562240039588324, 28.834643183490357)\n","LB : 29.59\n","    \n","- is_holiday\n","mean : (0.2715865953678639, 29.698993530910787)\n","LB : 29.610441\n","    \n","+ is_holiday\n","LB : 29.463389\n","    \n","\n","+ continuous equal value\n","mean : (0.2642950983875577, 29.08533340630285) : nmax=3, \n","        (0.2635035317889631, 29.034958873968534) : nmax=4, \n","        (0.263370016717205, 29.05395734892656) : nmax=5,\n","        (0.26332217195667157, 29.041987147018972) : nmax=6,\n","        (0.2629562507335404, 29.004030535332717) : nmax=7,\n","LB : \n","    \n","+ continuous equal value + is_holiday => 은선\n","mean : (0.2572715264515067, 28.8154113691253) : nmax=7,\n","        (0.25646055098412307, 28.823119972877404) : nmax=25\n","LB : 29.753622(nmax=7 version)\n","    \n","\n","\n","min\n","mean : (0.25621980207812756, 28.69560261882844)\n","LB : \n","    \n","min, working time\n","mean : (0.2566664670312808, 28.68228620004992)\n","LB : \n","\n","\n","    \n","    \n","    \n","\n","1. 실험요소, nan값 많은, prior target 지우는가?\n","2. -prediction 0 or min : (0.25621980207812756, 28.69560261882844), 29.11\n","3. feature combine\n","4. weather data\n","5. xgb, seed ensemble\n","\n","\n","\n","min : np.mean(rmse_list), np.mean(smape_list)  \n","    \n","    \n","nan process(dropna version and prior target) -> 3sigma\n","mean : (0.2617307645486781, 29.029936608903007)\n","LB : \n","    \n","    \n","nan process(dropna version and prior target) -> 3sigma + -prediction.fillna(train_df['target'].min())\n","mean : (0.2617263166484412, 28.885100489166994)\n","LB : "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"89Nr6OGVn3y3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fUfMDoFHNVfl","colab_type":"code","outputId":"1809ee6e-134a-4333-b075-7554ae077367","executionInfo":{"status":"ok","timestamp":1572019411928,"user_tz":-540,"elapsed":614,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = 'drive/My Drive/11dacon/submit/'\n","\n","submit_df.to_csv(path+'holiday3.csv', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_IDwoVtQP7lY","colab_type":"code","colab":{}},"source":["submit_df.head(15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CupuIIoESTP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}