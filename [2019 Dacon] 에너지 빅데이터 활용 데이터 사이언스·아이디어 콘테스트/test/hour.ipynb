{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hour.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nFpHQC0260Oc","colab_type":"code","outputId":"4349904f-44e1-42e8-cc73-a0b0cdce2428","executionInfo":{"status":"ok","timestamp":1571797617482,"user_tz":-540,"elapsed":40189,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":829}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import gc\n","import tqdm\n","import datetime\n","import random\n","from collections import defaultdict\n","from sklearn.neural_network import MLPRegressor\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import Lasso, Ridge\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit, GroupKFold\n","\n","# model\n","import xgboost as xgb\n","import lightgbm as lgb\n","\n","# evaluation\n","from sklearn.metrics import mean_squared_error\n","\n","# install\n","!pip install workalendar\n","from workalendar.asia import SouthKorea"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Collecting workalendar\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/3b/0674dab5f7b9878c4907ad9f833575fc23c58616c126c65cd21b9fd2bedb/workalendar-7.0.0-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from workalendar) (2018.9)\n","Requirement already satisfied: lunardate in /usr/local/lib/python3.6/dist-packages (from workalendar) (0.2.0)\n","Collecting skyfield-data (from workalendar)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/46/666a4b44709badf6e11b8b77a7aeefebababc1648f46a893f9f8642e99b3/skyfield_data-0.1.0-py2.py3-none-any.whl (16.0MB)\n","\u001b[K     |████████████████████████████████| 16.0MB 34.6MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from workalendar) (2.5.3)\n","Collecting pyCalverter (from workalendar)\n","  Downloading https://files.pythonhosted.org/packages/4f/5c/57c6853f7a5bc41fc9da7651ae67b9c76381083742613faa7381724081e9/pyCalverter-1.6.1.tar.gz\n","Collecting skyfield (from workalendar)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9c/4a9879460dddac5bda8d7e8b8eb6159093d2b285077d085ff78d4f02a2bc/skyfield-1.13.tar.gz (224kB)\n","\u001b[K     |████████████████████████████████| 225kB 38.9MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=1.0 in /usr/local/lib/python3.6/dist-packages (from workalendar) (41.4.0)\n","Collecting pyluach (from workalendar)\n","  Downloading https://files.pythonhosted.org/packages/79/2c/4f413270a621dd6238fa67d9db81efd5edc02b44a5b1b8510552f643fc58/pyluach-1.0.1-py3-none-any.whl\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->workalendar) (1.12.0)\n","Collecting jplephem>=2.3 (from skyfield->workalendar)\n","  Downloading https://files.pythonhosted.org/packages/14/6f/354fd50e625a66c7be3f08095c0e1fa389c75453858acf2689ffa9c4fc54/jplephem-2.9.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from skyfield->workalendar) (1.16.5)\n","Collecting sgp4>=1.4 (from skyfield->workalendar)\n","  Downloading https://files.pythonhosted.org/packages/d2/00/3f3699203176017211a71fe16e3fa71bae946ac92ade77d5a2ffc5da8576/sgp4-1.4.tar.gz\n","Building wheels for collected packages: pyCalverter, skyfield, jplephem, sgp4\n","  Building wheel for pyCalverter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyCalverter: filename=pyCalverter-1.6.1-cp36-none-any.whl size=4200 sha256=b20ec9c22d11d964675d70106151bb913b7828cc05681a09b7e9583158f6fbad\n","  Stored in directory: /root/.cache/pip/wheels/77/4d/86/db4ff4eca6178dbbd5a365d095f97f6021e2a48f09908be79c\n","  Building wheel for skyfield (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for skyfield: filename=skyfield-1.13-cp36-none-any.whl size=253163 sha256=f09fecc71c637e31b617b72e83b280902779a827e347f2c4081772ab32c1204c\n","  Stored in directory: /root/.cache/pip/wheels/76/3d/1c/afe30b6c7a526ba23b63c1947c64cc7b9142a6e78858fe2384\n","  Building wheel for jplephem (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jplephem: filename=jplephem-2.9-cp36-none-any.whl size=41100 sha256=968b5d1e9b3a4a64db189b269a94af6d523173f0f467f564030002b03b1eb559\n","  Stored in directory: /root/.cache/pip/wheels/13/d3/06/3799163edac5d1f454832143f7730413dcc56f42acfbb9f0d3\n","  Building wheel for sgp4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgp4: filename=sgp4-1.4-cp36-none-any.whl size=35410 sha256=a2663d3dc0da225dde4466f3cb4deedad6969a413f156e2550c7e460c5a00aa6\n","  Stored in directory: /root/.cache/pip/wheels/6d/e2/42/5dc20daf2ba62ae03dc8abe10744ee67d9452df447dac561db\n","Successfully built pyCalverter skyfield jplephem sgp4\n","Installing collected packages: skyfield-data, pyCalverter, jplephem, sgp4, skyfield, pyluach, workalendar\n","Successfully installed jplephem-2.9 pyCalverter-1.6.1 pyluach-1.0.1 sgp4-1.4 skyfield-1.13 skyfield-data-0.1.0 workalendar-7.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pJc8YZ3k63Rc","colab_type":"code","outputId":"10fd4a43-acc5-44ef-a582-7ec0ed4002c1","executionInfo":{"status":"ok","timestamp":1571797618301,"user_tz":-540,"elapsed":19382,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = 'drive/My Drive/11dacon/data/'\n","\n","def seed_everything(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    \n","from numba import jit\n","import math\n","\n","@jit\n","def smape_fast(y_true, y_pred, exp=True):\n","    \n","    if exp:\n","        y_true = np.expm1(np.array(y_true))\n","        y_pred = np.expm1(np.array(y_pred))\n","    else:\n","        y_true = np.array(y_true)\n","        y_pred = np.array(y_pred)\n","        \n","    out = 0\n","    for i in range(y_true.shape[0]):\n","        a = y_true[i]\n","        b = y_pred[i]\n","        c = a+b\n","        if c == 0:\n","            continue\n","        out += math.fabs(a - b) / c\n","    out *= (200.0 / y_true.shape[0])\n","    return out\n","\n","def rmse(y_true, y_pred, exp=True):\n","    if exp:\n","        return np.sqrt(mean_squared_error(np.expm1(y_true), np.expm1(y_pred)))\n","    else:\n","        return np.sqrt(mean_squared_error(y_true, y_pred))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0WnZkSUA7Ar1","colab_type":"code","colab":{}},"source":["train = pd.read_csv(path+'train.csv')\n","test = pd.read_csv(path+'test.csv')\n","sub = pd.read_csv(path+'submission.csv')\n","\n","holidays = pd.concat([pd.Series(np.array(SouthKorea().holidays(2018))[:, 0]), pd.Series(np.array(SouthKorea().holidays(2017))[:, 0]), pd.Series(np.array(SouthKorea().holidays(2016))[:, 0])]).reset_index(drop=True)\n","\n","weather3 = pd.read_csv(path+'weather_hour.csv', encoding='cp949').iloc[:, [1, 2, 3, 4, 5, 7, 8]]\n","weather3.columns = ['일시', '기온', '강수량', '풍속', '습도', '날씨', '전운량']\n","\n","weather3['날씨'] = LabelEncoder().fit_transform(weather3['날씨'].fillna('no value'))\n","weather3 = weather3.fillna(0)\n","weather3['일시'] = pd.to_datetime(weather3['일시'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-NWlZYWD80C","colab_type":"code","colab":{}},"source":["def merge(train):\n","    train_df = pd.DataFrame()\n","    for col in train.columns[1:]:\n","        temp = train[['Time', col]].dropna().rename(columns={col:'target'})\n","        temp['house'] = int(col.replace('X', ''))\n","        temp = temp[temp['Time']>='2018-01-01'].reset_index(drop=True)\n","\n","        temp['Time'] = pd.to_datetime(temp['Time'])\n","        temp['date'] = temp['Time'].dt.date\n","        temp['holiday'] = temp['date'].isin(holidays).astype(int)\n","        temp['week'] = temp['Time'].dt.week\n","        temp['weekday'] = temp['Time'].dt.weekday\n","        temp['hour'] = temp['Time'].dt.hour\n","        temp['working_hour'] = temp['hour'].map({0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, \n","                                                        9:1, 10:1, 11:1, 12:1, 13:1, 14:1, 15:1, 16:1, 17:1, \n","                                                        18:1, 19:1, 20:1, 21:0, 22:0, 23:0, 24:0})\n","        temp['is_weekend'] = temp['Time'].dt.weekday.map({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:1})\n","        temp['is_weekend_holiday'] = (temp['is_weekend']+temp['holiday']).map({0:0, 1:1, 2:1})\n","        \n","        temp['target_mean'] = temp['target'].mean()\n","        temp['target_min'] = temp['target'].min()\n","        temp['target_max'] = temp['target'].max()\n","        temp['target_std'] = temp['target'].std()\n","        temp['target_quan1'] = temp['target'].quantile(.25)\n","        temp['target_quan2'] = temp['target'].quantile(.5)\n","        temp['target_quan3'] = temp['target'].quantile(.75)\n","        temp['target_quan4'] = temp['target'].quantile(.125)\n","        temp['target_quan5'] = temp['target'].quantile(.375)\n","        temp['target_quan6'] = temp['target'].quantile(.675)\n","        temp['target_quan7'] = temp['target'].quantile(.925)\n","        \n","        \n","        temp_week = temp.groupby('week')['target'].mean().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['week'] = temp_week['week']+1\n","        temp_week = temp_week.set_index('week').to_dict()['prior_target']\n","        temp['prior_target_mean'] = temp['week'].map(temp_week)\n","        temp_week = temp.groupby('week')['target'].min().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['week'] = temp_week['week']+1\n","        temp_week = temp_week.set_index('week').to_dict()['prior_target']\n","        temp['prior_target_min'] = temp['week'].map(temp_week)\n","        temp_week = temp.groupby('week')['target'].max().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['week'] = temp_week['week']+1\n","        temp_week = temp_week.set_index('week').to_dict()['prior_target']\n","        temp['prior_target_max'] = temp['week'].map(temp_week)\n","        temp_week = temp.groupby('week')['target'].std().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['week'] = temp_week['week']+1\n","        temp_week = temp_week.set_index('week').to_dict()['prior_target']\n","        temp['prior_target_std'] = temp['week'].map(temp_week)\n","        temp_week = temp.groupby('week')['target'].quantile(.25).reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['week'] = temp_week['week']+1\n","        temp_week = temp_week.set_index('week').to_dict()['prior_target']\n","        temp['prior_target_quan1'] = temp['week'].map(temp_week)\n","        temp_week = temp.groupby('week')['target'].quantile(.5).reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['week'] = temp_week['week']+1\n","        temp_week = temp_week.set_index('week').to_dict()['prior_target']\n","        temp['prior_target_quan2'] = temp['week'].map(temp_week)\n","        temp_week = temp.groupby('week')['target'].quantile(.75).reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['week'] = temp_week['week']+1\n","        temp_week = temp_week.set_index('week').to_dict()['prior_target']\n","        temp['prior_target_quan3'] = temp['week'].map(temp_week)\n","        \n","        temp_week = temp.groupby('month')['target'].mean().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['month'] = temp_week['month']+1\n","        temp_week = temp_week.set_index('month').to_dict()['prior_target']\n","        temp['prior_target_mean_month'] = temp['month'].map(temp_week)\n","        temp_week = temp.groupby('month')['target'].min().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['month'] = temp_week['month']+1\n","        temp_week = temp_week.set_index('month').to_dict()['prior_target']\n","        temp['prior_target_min_month'] = temp['month'].map(temp_week)\n","        temp_week = temp.groupby('month')['target'].max().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['month'] = temp_week['month']+1\n","        temp_week = temp_week.set_index('month').to_dict()['prior_target']\n","        temp['prior_target_max_month'] = temp['month'].map(temp_week)\n","        temp_week = temp.groupby('month')['target'].std().reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['month'] = temp_week['month']+1\n","        temp_week = temp_week.set_index('month').to_dict()['prior_target']\n","        temp['prior_target_std_month'] = temp['month'].map(temp_week)\n","        temp_week = temp.groupby('month')['target'].quantile(.25).reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['month'] = temp_week['month']+1\n","        temp_week = temp_week.set_index('month').to_dict()['prior_target']\n","        temp['prior_target_quan1_month'] = temp['month'].map(temp_week)\n","        temp_week = temp.groupby('month')['target'].quantile(.5).reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['month'] = temp_week['month']+1\n","        temp_week = temp_week.set_index('month').to_dict()['prior_target']\n","        temp['prior_target_quan2_month'] = temp['month'].map(temp_week)\n","        temp_week = temp.groupby('month')['target'].quantile(.75).reset_index().rename(columns={'target':'prior_target'})\n","        temp_week['month'] = temp_week['month']+1\n","        temp_week = temp_week.set_index('month').to_dict()['prior_target']\n","        temp['prior_target_quan3_month'] = temp['month'].map(temp_week)\n","        \n","        temp = temp.dropna()\n","        \n","        train_df = pd.concat([train_df, temp]).reset_index(drop=True)\n","\n","    train_df.rename(columns={'Time':'일시'}, inplace=True)\n","    train_df = pd.merge(train_df, weather3, how='left', on='일시')\n","    \n","    return train_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOhOLlL3YtSH","colab_type":"code","colab":{}},"source":["train_df2 = merge(train)\n","train_df = merge(test)\n","\n","train_df = pd.concat([train_df, train_df2]).reset_index(drop=True)\n","\n","train_df['target'] = np.log1p(train_df['target'])\n","\n","test_df = train_df[train_df['일시']>='2018-06-30 00'].reset_index(drop=True)\n","train_df = train_df[train_df['일시']<'2018-06-30 00'].reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lrli4zqKTgR3","colab_type":"code","outputId":"4c7b0f78-e567-4b35-a87a-d1adc3684120","executionInfo":{"status":"ok","timestamp":1571745089888,"user_tz":-540,"elapsed":5997,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":809}},"source":["params = {\n","    'objective':'reg:squarederror',\n","    'n_estimators':100,\n","    'max_depth':2**3,\n","    'learning_rate':0.1,\n","#     'gpu_id':0,\n","    'tree_method':'gpu_hist',\n","#     'n_jobs':-1,\n","    'seed':42\n","}\n","\n","oof = np.zeros(len(train_df))\n","pred = np.zeros(len(test_df))\n","\n","feature = [i for i in train_df.columns if i not in ['target', '일시', 'date']]\n","kf = KFold(n_splits=5, random_state=42, shuffle=False)\n","gkf = GroupKFold(n_splits=5)\n","best_iterations = []\n","\n","for trn_idx, val_idx in kf.split(train_df):\n","# for trn_idx, val_idx in gkf.split(train_df, groups=train_df['house']):\n","    tt = xgb.DMatrix(train_df.loc[trn_idx, feature], train_df.loc[trn_idx, ['target']])\n","    vv = xgb.DMatrix(train_df.loc[val_idx, feature], train_df.loc[val_idx, ['target']])\n","    \n","    model = xgb.train(params, tt, num_boost_round=5000, evals=[(tt, 'train'), (vv, 'val')], early_stopping_rounds=200, verbose_eval=100)\n","    \n","    oof[val_idx] = model.predict(xgb.DMatrix(train_df.loc[val_idx, feature]))\n","    pred += model.predict(xgb.DMatrix(test_df[feature]))/5\n","    best_iterations.append(model.best_iteration)\n","smape_fast(test_df['target'], pred, False), rmse(test_df['target'], pred, False), best_iterations, np.mean(best_iterations)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0]\ttrain-rmse:0.272047\tval-rmse:0.356897\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[100]\ttrain-rmse:0.124895\tval-rmse:0.21508\n","[200]\ttrain-rmse:0.120044\tval-rmse:0.215112\n","[300]\ttrain-rmse:0.116839\tval-rmse:0.215539\n","Stopping. Best iteration:\n","[135]\ttrain-rmse:0.122627\tval-rmse:0.214759\n","\n","[0]\ttrain-rmse:0.293754\tval-rmse:0.278319\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[100]\ttrain-rmse:0.131425\tval-rmse:0.141662\n","[200]\ttrain-rmse:0.125567\tval-rmse:0.141293\n","[300]\ttrain-rmse:0.121998\tval-rmse:0.141372\n","Stopping. Best iteration:\n","[190]\ttrain-rmse:0.126016\tval-rmse:0.141195\n","\n","[0]\ttrain-rmse:0.298346\tval-rmse:0.257881\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[100]\ttrain-rmse:0.131992\tval-rmse:0.137966\n","[200]\ttrain-rmse:0.125795\tval-rmse:0.136985\n","[300]\ttrain-rmse:0.122021\tval-rmse:0.136663\n","[400]\ttrain-rmse:0.118873\tval-rmse:0.136536\n","[500]\ttrain-rmse:0.116389\tval-rmse:0.136527\n","[600]\ttrain-rmse:0.114446\tval-rmse:0.136649\n","Stopping. Best iteration:\n","[468]\ttrain-rmse:0.117227\tval-rmse:0.136476\n","\n","[0]\ttrain-rmse:0.292432\tval-rmse:0.283586\n","Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n","\n","Will train until val-rmse hasn't improved in 200 rounds.\n","[100]\ttrain-rmse:0.130855\tval-rmse:0.147984\n","[200]\ttrain-rmse:0.124776\tval-rmse:0.147075\n","[300]\ttrain-rmse:0.121089\tval-rmse:0.14725\n","[400]\ttrain-rmse:0.118227\tval-rmse:0.147393\n","Stopping. Best iteration:\n","[236]\ttrain-rmse:0.123162\tval-rmse:0.147024\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OytkGLmqXtr_","colab_type":"code","outputId":"3eaa7dbc-e071-48ba-957f-f536442a6e27","executionInfo":{"status":"ok","timestamp":1571745109665,"user_tz":-540,"elapsed":3843,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["# predictions\n","train_df = pd.concat([train_df, test_df]).reset_index(drop=True)\n","params = {\n","    'objective':'reg:squarederror',\n","    'n_estimators':10000,\n","    'max_depth':2**3,\n","    'learning_rate':0.03,\n","    'n_jobs':-1,\n","    'seed':42\n","}\n","\n","temp = pd.DataFrame(pd.Series(pd.date_range('2018-07-01', '2018-11-01')).dt.to_period('m').unique(), columns=['일시'])\n","temp = pd.merge(temp, weather1, how='left', on='일시')\n","\n","test_df = pd.DataFrame()\n","for col in sub['meter_id'].apply(lambda x: x.split('X')[1]):\n","    temp['house'] = int(col)\n","    test_df = pd.concat([test_df, temp])\n","test_df = pd.merge(test_df, day_range, how='left', on='일시')\n","test_df['num_day'] = test_df['평일'] + test_df['주말_공휴일']\n","test_df = pd.merge(test_df, train_df[['house', 'target_mean', 'target_min', 'target_max', 'target_std', 'target_quan1', 'target_quan2', 'target_quan3']].drop_duplicates(), how='left', on='house')\n","\n","test_df = test_df.reset_index(drop=True)\n","pred = np.zeros(len(test_df))\n","\n","for seed in [42, 43, 44, 45, 46]:\n","    params['seed']=seed\n","    \n","    tt = xgb.DMatrix(train_df[feature], train_df[['target']])\n","    model = xgb.train(params, tt, num_boost_round=250, evals=[(tt, 'train')], verbose_eval=100)\n","    pred += model.predict(xgb.DMatrix(test_df[feature]))/5\n","pred_xgb = pred.copy()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0]\ttrain-rmse:4.88609\n","[100]\ttrain-rmse:0.291863\n","[200]\ttrain-rmse:0.073943\n","[249]\ttrain-rmse:0.062123\n","[0]\ttrain-rmse:4.88609\n","[100]\ttrain-rmse:0.291863\n","[200]\ttrain-rmse:0.073943\n","[249]\ttrain-rmse:0.062123\n","[0]\ttrain-rmse:4.88609\n","[100]\ttrain-rmse:0.291863\n","[200]\ttrain-rmse:0.073943\n","[249]\ttrain-rmse:0.062123\n","[0]\ttrain-rmse:4.88609\n","[100]\ttrain-rmse:0.291863\n","[200]\ttrain-rmse:0.073943\n","[249]\ttrain-rmse:0.062123\n","[0]\ttrain-rmse:4.88609\n","[100]\ttrain-rmse:0.291863\n","[200]\ttrain-rmse:0.073943\n","[249]\ttrain-rmse:0.062123\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n-RbM4hnLmyk","colab_type":"code","outputId":"4d33917b-5da5-4c69-e0c8-0f7d8ec1bbad","executionInfo":{"status":"ok","timestamp":1571797471508,"user_tz":-540,"elapsed":709977,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["params = {\n","    'objective':'regression',\n","    'boosting_type':'gbdt',\n","    'metric':'rmse',\n","    'n_jobs':-1,\n","    'learning_rate':0.1,\n","    'num_leaves': 2**8,\n","    'max_depth':-1,\n","    'tree_learner':'serial',\n","    'colsample_bytree': 0.7,\n","    'subsample_freq':1,\n","    'subsample':0.7,\n","    'reg_alpha':0.1,\n","    'reg_lambda':0.1,\n","    'n_estimators':10000,\n","    'max_bin':255,\n","    'verbose':-1,\n","    'seed': 42,\n","    'early_stopping_rounds':100\n","}\n","\n","oof = np.zeros(len(train_df))\n","pred = np.zeros(len(test_df))\n","\n","feature = [i for i in train_df.columns if i not in ['target', '일시', 'date', 'week']]\n","kf = KFold(n_splits=5, random_state=42, shuffle=False)\n","gkf = GroupKFold(n_splits=5)\n","best_iterations = []\n","\n","for trn_idx, val_idx in kf.split(train_df):\n","# for trn_idx, val_idx in gkf.split(train_df, groups=train_df['house']):\n","    tt = lgb.Dataset(train_df.loc[trn_idx, feature], train_df.loc[trn_idx, ['target']])\n","    vv = lgb.Dataset(train_df.loc[val_idx, feature], train_df.loc[val_idx, ['target']])\n","    \n","    model = lgb.train(params, tt, valid_sets=[tt, vv], early_stopping_rounds=200, verbose_eval=0)\n","    \n","    pred += model.predict(test_df[feature])/5\n","    best_iterations.append(model.best_iteration)\n","    print('HH')\n","    \n","smape_fast(test_df['target'], pred, False), rmse(test_df['target'], pred, False), best_iterations, np.mean(best_iterations)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["HH\n","HH\n","HH\n","HH\n","HH\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(37.27816052839377, 0.1918552311279994, [71, 171, 387, 245, 185], 211.8)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"ul-CtB8JGIw0","colab_type":"code","colab":{}},"source":["# week : overfit\n","# all summary statistics : 41.9\n","# prior weekly summary statistics : 40.32\n","\n","# 2가지 모두"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6o5jvTFLnhv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"outputId":"e5d2baa8-cebe-416b-c04f-ae8ab9b08be0","executionInfo":{"status":"ok","timestamp":1571747539189,"user_tz":-540,"elapsed":12659,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}}},"source":["# predictions\n","train_df = pd.concat([train_df, test_df]).reset_index(drop=True)\n","params = {\n","    'objective':'regression',\n","    'boosting_type':'gbdt',\n","    'metric':'rmse',\n","    'n_jobs':-1,\n","    'learning_rate':0.03,\n","    'num_leaves': 2**8,\n","    'max_depth':-1,\n","    'subsample':0.7,\n","    'reg_alpha':0.1,\n","    'reg_lambda':0.1,\n","    'n_estimators':100,\n","    'max_bin':255,\n","    'verbose':-1,\n","    'seed': 42,\n","    'early_stopping_rounds':100\n","}\n","\n","temp = pd.DataFrame(pd.date_range('2018-07-01', '2018-07-02', freq='h'), columns=['일시']).loc[:23]\n","temp = pd.merge(temp, weather3, how='left', on='일시')\n","\n","test_df = pd.DataFrame()\n","for col in sub['meter_id'].apply(lambda x: x.split('X')[1]):\n","    temp['house'] = int(col)\n","    test_df = pd.concat([test_df, temp])\n","test_df\n","\n","test_df['date'] = test_df['일시'].dt.date\n","test_df['holiday'] = test_df['date'].isin(holidays).astype(int)\n","test_df['weekday'] = test_df['일시'].dt.weekday\n","test_df['hour'] = test_df['일시'].dt.hour\n","test_df['working_hour'] = test_df['hour'].map({0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, \n","                                                9:1, 10:1, 11:1, 12:1, 13:1, 14:1, 15:1, 16:1, 17:1, \n","                                                18:1, 19:1, 20:1, 21:0, 22:0, 23:0, 24:0})\n","test_df['is_weekend'] = test_df['일시'].dt.weekday.map({0:0, 1:0, 2:0, 3:0, 4:0, 5:1, 6:1})\n","test_df['is_weekend_holiday'] = (test_df['is_weekend']+test_df['holiday']).map({0:0, 1:1, 2:1})\n","test_df = pd.merge(test_df, train_df[['house', 'target_mean', 'target_min', 'target_max', 'target_std', 'target_quan1', 'target_quan2', 'target_quan3']], how='left', on='house')\n","test_df = test_df.reset_index(drop=True)\n","\n","pred = np.zeros(len(test_df))\n","\n","for seed in [42, 43, 44, 45, 46]:\n","    params['seed']=seed\n","    \n","    tt = lgb.Dataset(train_df[feature], train_df[['target']])\n","    model = lgb.train(params, tt, valid_sets=[tt], verbose_eval=300)\n","    pred += model.predict(test_df[feature])/5\n","pred_lgb = pred.copy()"],"execution_count":55,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's rmse: 0.117859\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's rmse: 0.117859\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's rmse: 0.117859\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's rmse: 0.117859\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's rmse: 0.117859\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2zfJpsSGUlbd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOf3Y_r4XbA5","colab_type":"code","colab":{}},"source":["# pred = pred_lgb*0.5 + pred_xgb*0.5\n","test_df['pred'] = np.expm1(pred_lgb)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVFYtBR-XbI1","colab_type":"code","colab":{}},"source":["sub_df = test_df.groupby(['house', '일시'])['pred'].sum().unstack().reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDIKEI6RXbNK","colab_type":"code","outputId":"a9072336-a0a0-43d9-ee4a-ff077dc3c230","executionInfo":{"status":"ok","timestamp":1571747598089,"user_tz":-540,"elapsed":1068,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = 'drive/My Drive/11dacon/submit/'\n","\n","sub_df.to_csv(path+'hour_prediction_lgb_add_feature.csv', index=False)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j5LBKbEcXbV3","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dt6CHgWpXbZe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"57590194-5ca3-4f75-e03e-5f74aef2be3a","executionInfo":{"status":"ok","timestamp":1571819300509,"user_tz":-540,"elapsed":943,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = 'drive/My Drive/11dacon/submit/'\n","a = pd.read_pickle(path+'aaa.pkl')\n","a.to_csv(path+'hour_predicion_lgb.csv', index=False)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZOtzlUl8Vqe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tw4XrBTX7_qe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfsuaWXU7_tW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}